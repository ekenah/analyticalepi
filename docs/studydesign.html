<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>7&nbsp; Cohort and Case-Control Studies – Analytical Epidemiology</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./validity.html" rel="next">
<link href="./survival.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-747bc48f972f7c4036e4d8e8c6d9e55a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<script>
  window.MathJax = {
    loader: {load: ['[tex]/centernot']},
    tex: {
      macros: {
        A: "\\mathcal\{A\}",
        approxsim: "\\stackrel\{\\text\{approx\}\}\{\\sim\}",
        AR: "\\text\{AR\}",
        B: "\\mathcal\{B\}",
        Bernoulli: ["\\operatorname\{Bernoulli\}"],
        binomial: ["\\operatorname\{binomial\}"],
        C: "\\mathcal\{C\}",
        chisqH: "\\chi^2_\\text\{H\}",
        chisqP: "\\chi^2_\\text\{P\}",
        chisqPobs: "\\chi^2_\\text\{Pobs\}",
        cHR: "\\text\{cHR\}",
        CHR: "\\text\{CHR\}",
        cloglog: ["\\operatorname\{cloglog\}"],
        comp: "\\mathsf\{C\}",
        Cov: ["\\operatorname\{Cov\}"],
        crude: "\\text\{crude\}",
        D: "\\mathcal\{D\}",
        data: "\\text\{data\}",
        dif: "\\text\{d\}",
        Dminus: "\\text\{D\}^-",
        Dplus: "\\text\{D\}^+",
        E: ["\\operatorname\{\\mathbb\{E\}\}"],
        ESSR: "\\text\{ESSR\}",
        expit: ["\\operatorname\{expit\}"],
        given: ["\\, #1| \\, ", 1],
        HR: "\\text\{HR\}",
        indep: "\\perp\\!\\!\\!\\perp",
        indicator: "\\mathbb\{1\}",
        iptw: ["\\operatorname\{iptw\}"],
        ipw: ["\\operatorname\{ipw\}"],
        IRR: "\\text\{IRR\}",
        K: "\\mathcal\{K\}",
        logit: ["\\operatorname\{logit\}"],
        margins: "\\text\{margins\}",
        obs: "\\text\{obs\}",
        odds: ["\\operatorname\{odds\}"],
        OR: "\\text\{OR\}",
        pa: "\\text\{pa\}",
        PAR: "\\text\{PAR\}",
        pcrude: "p^*\_\\text\{crude\}",
        pmarg: "p\_\\text\{marg\}",
        Prstd: "\\Pr\\nolimits\_\\text\{std\}",
        ptrue: "p_\{\\text\{true\}\}",
        R: "\\mathcal\{R\}",
        RD: "\\text\{RD\}",
        RR: "\\text\{RR\}",
        sens: "\\text\{sens\}",
        siptw: ["\\operatorname\{siptw\}"],
        spec: "\\text\{spec\}",
        std: "\\text\{std\}",
        supp: ["\\operatorname\{supp\}"],
        tcens: "t^\\text\{cens\}",
        tentry: "t^\\text\{entry\}",
        tevent: "t^\\text\{event\}",
        texit: "t^\\text\{exit\}",
        Tminus: "\\text\{T\}^-",
        tonset: "t^\\text\{onset\}",
        Tplus: "\\text\{T\}^+",
        transpose: "\\mathsf{T}",
        trec: "t^\\text\{rec\}",
        true: "\\text\{true\}",
        twobytwo: "2 \\times 2",
        vand: "\\text\{ and \}",
        Var: ["\\operatorname\{Var\}"],
        Xminus: "\\text\{X\}^-",
        Xobs: "\\text\{X\}^\\text\{obs\}",
        Xplus: "\\text\{X\}^+"
      }
    }
  };
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./studydesign.html">Study Design and Measures of Association</a></li><li class="breadcrumb-item"><a href="./studydesign.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Cohort and Case-Control Studies</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Analytical Epidemiology</a> 
        <div class="sidebar-tools-main">
    <a href="./Analytical-Epidemiology.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Defining and Measuring Disease Occurrence</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Probability, Random Variables, and Disease Occurrence</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./condprob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Conditional Probability and Diagnostic Tests</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mlestimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Maximum Likelihood Estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Bayesian Estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./longitudinal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Longitudinal Data, Rates, and Counts</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./survival.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">One-Sample Survival Analysis</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Study Design and Measures of Association</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./studydesign.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Cohort and Case-Control Studies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./validity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Internal and External Validity</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cohort.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Measures of Association in Cohort Studies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./survival2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Two-Sample Survival Analysis and the Cox Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./casecontrol.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Design and Analysis of Case-Control and Case-Cohort studies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bayes2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Bayesian analysis of cohort and case-control studies</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Principles of Causal Inference</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./causality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Causality in Public Health</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./counterfactuals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Potential Outcomes and Attributable Risk</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dags.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Confounding and Selection Bias on DAGs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./swigs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Confounding and Selection Bias on SWIGs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./standardization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Causal Effects and Standardization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./geometry.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Geometry of Causal Inference</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Epidemologic and Statistical Methods for Causal Inference</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stratification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Stratified Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./matching.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Matching in Cohort and Case-Control Studies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./outcomereg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Multivariable Outcome Regression Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./propensityscores.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Propensity Scores</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./marginalstructural.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Marginal Structural Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./calculus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Calculus</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="2">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sampling-from-a-population" id="toc-sampling-from-a-population" class="nav-link active" data-scroll-target="#sampling-from-a-population"><span class="header-section-number">7.1</span> Sampling from a population</a>
  <ul class="collapse">
  <li><a href="#sec-hypergeometric" id="toc-sec-hypergeometric" class="nav-link" data-scroll-target="#sec-hypergeometric"><span class="header-section-number">7.1.1</span> Hypergeometric distribution*</a></li>
  <li><a href="#sec-multinomial" id="toc-sec-multinomial" class="nav-link" data-scroll-target="#sec-multinomial"><span class="header-section-number">7.1.2</span> Multinomial distribution</a></li>
  </ul></li>
  <li><a href="#sec-2x2independence" id="toc-sec-2x2independence" class="nav-link" data-scroll-target="#sec-2x2independence"><span class="header-section-number">7.2</span> Hypothesis tests for independence in a 2x2 table</a>
  <ul class="collapse">
  <li><a href="#sec-indep-condprob" id="toc-sec-indep-condprob" class="nav-link" data-scroll-target="#sec-indep-condprob"><span class="header-section-number">7.2.1</span> Equality of conditional probabilities</a></li>
  <li><a href="#hypergeometric-chi-squared-test" id="toc-hypergeometric-chi-squared-test" class="nav-link" data-scroll-target="#hypergeometric-chi-squared-test"><span class="header-section-number">7.2.2</span> Hypergeometric chi-squared test</a></li>
  <li><a href="#pearsons-chi-squared-test" id="toc-pearsons-chi-squared-test" class="nav-link" data-scroll-target="#pearsons-chi-squared-test"><span class="header-section-number">7.2.3</span> Pearson’s chi-squared test</a></li>
  <li><a href="#small-samples-and-exact-tests" id="toc-small-samples-and-exact-tests" class="nav-link" data-scroll-target="#small-samples-and-exact-tests"><span class="header-section-number">7.2.4</span> Small samples and exact tests*</a></li>
  </ul></li>
  <li><a href="#cohort-studies" id="toc-cohort-studies" class="nav-link" data-scroll-target="#cohort-studies"><span class="header-section-number">7.3</span> Cohort studies</a>
  <ul class="collapse">
  <li><a href="#selection-by-exposure" id="toc-selection-by-exposure" class="nav-link" data-scroll-target="#selection-by-exposure"><span class="header-section-number">7.3.1</span> Selection by exposure</a></li>
  <li><a href="#score-test-for-independence-in-a-cohort-study" id="toc-score-test-for-independence-in-a-cohort-study" class="nav-link" data-scroll-target="#score-test-for-independence-in-a-cohort-study"><span class="header-section-number">7.3.2</span> Score test for independence in a cohort study*</a></li>
  <li><a href="#sec-optim-cohort" id="toc-sec-optim-cohort" class="nav-link" data-scroll-target="#sec-optim-cohort"><span class="header-section-number">7.3.3</span> Optimal sampling by exposure</a></li>
  </ul></li>
  <li><a href="#case-control-studies" id="toc-case-control-studies" class="nav-link" data-scroll-target="#case-control-studies"><span class="header-section-number">7.4</span> Case-control studies</a>
  <ul class="collapse">
  <li><a href="#selection-by-disease" id="toc-selection-by-disease" class="nav-link" data-scroll-target="#selection-by-disease"><span class="header-section-number">7.4.1</span> Selection by disease</a></li>
  <li><a href="#score-test-for-independence-in-a-case-control-study" id="toc-score-test-for-independence-in-a-case-control-study" class="nav-link" data-scroll-target="#score-test-for-independence-in-a-case-control-study"><span class="header-section-number">7.4.2</span> Score test for independence in a case-control study*</a></li>
  <li><a href="#optimal-sampling-by-disease" id="toc-optimal-sampling-by-disease" class="nav-link" data-scroll-target="#optimal-sampling-by-disease"><span class="header-section-number">7.4.3</span> Optimal sampling by disease</a></li>
  </ul></li>
  <li><a href="#sec-design-choice" id="toc-sec-design-choice" class="nav-link" data-scroll-target="#sec-design-choice"><span class="header-section-number">7.5</span> Choice of study design</a>
  <ul class="collapse">
  <li><a href="#sec-ORdesign" id="toc-sec-ORdesign" class="nav-link" data-scroll-target="#sec-ORdesign"><span class="header-section-number">7.5.1</span> Odds ratio</a></li>
  <li><a href="#imbalance-and-efficiency-on-a-fixed-budget" id="toc-imbalance-and-efficiency-on-a-fixed-budget" class="nav-link" data-scroll-target="#imbalance-and-efficiency-on-a-fixed-budget"><span class="header-section-number">7.5.2</span> Imbalance and efficiency on a fixed budget</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./studydesign.html">Study Design and Measures of Association</a></li><li class="breadcrumb-item"><a href="./studydesign.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Cohort and Case-Control Studies</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-studydesign" class="quarto-section-identifier"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Cohort and Case-Control Studies</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p>Like fire, the <span class="math inline">\(\chi^2\)</span> test is an excellent servant and a bad master. <span class="citation" data-cites="hill1965environment">(<a href="references.html#ref-hill1965environment" role="doc-biblioref">Hill 1965</a>)</span></p>
</blockquote>
<p>Some the most important questions in public health involve the association between a disease and a possible predictor or cause, which we call an exposure. Here, we consider testing the null hypothesis that exposure and disease are independent in a population based on a sample from that population. If exposure and disease are independent, an individual’s exposure status contains no information about their risk of disease and vice versa. For simplicity, we focus on a binary exposure and a binary disease outcome and we focus on association, not causation. It turns out this null hypothesis can be tested most efficiently when we sample study participants according to exposure or according to disease (but not both). Sampling by exposure leads to the <strong>cohort study</strong> design, and sampling by disease leads to the <strong>case-control</strong> study design.</p>
<section id="sampling-from-a-population" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="sampling-from-a-population"><span class="header-section-number">7.1</span> Sampling from a population</h2>
<p>Suppose we take a random sample of size <span class="math inline">\(n\)</span> from a population of size <span class="math inline">\(N \gg n\)</span> (i.e., <span class="math inline">\(N\)</span> is much greater than <span class="math inline">\(n\)</span>) and classify each individual in the sample by exposure and disease in a contingency table. We assume that each possible sample of size <span class="math inline">\(n\)</span> is equally likely. Each of the cell counts in the resulting 2x2 table is a random variable in the sample space <span class="math inline">\(\Omega_n\)</span> that consists of all possible samples of size <span class="math inline">\(n\)</span> from the population <span class="math inline">\(\Omega\)</span>. In <a href="#tbl-2x2random" class="quarto-xref">Table&nbsp;<span>7.1</span></a>, these random variables are <span class="math inline">\(\A\)</span>, <span class="math inline">\(\B\)</span>, <span class="math inline">\(\C\)</span>, and <span class="math inline">\(\D\)</span>. The random row totals are <span class="math inline">\(\R_1 = \A + \B\)</span> and <span class="math inline">\(\R_0 = \C + \D\)</span>, and the random column totals are <span class="math inline">\(\K_1 = \A + \C\)</span> and <span class="math inline">\(\K_0 = \B + \D\)</span>. The total sample size <span class="math inline">\(n\)</span> is fixed, which means that it is the same for every sample <span class="math inline">\(\omega_n \in \Omega_n\)</span>.</p>
<div id="tbl-2x2random" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-2x2random-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7.1: Random 2x2 table of exposure (<span class="math inline">\(X\)</span>) and disease (<span class="math inline">\(D\)</span>).
</figcaption>
<div aria-describedby="tbl-2x2random-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: center;"><span class="math inline">\(D = 1\)</span></th>
<th style="text-align: center;"><span class="math inline">\(D = 0\)</span></th>
<th style="text-align: center;">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(X = 1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\A\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\B\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\R_1\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(X = 0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\C\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\D\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\R_0\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Total</td>
<td style="text-align: center;"><span class="math inline">\(\K_1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\K_0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n\)</span></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p><a href="#tbl-2x2observed" class="quarto-xref">Table&nbsp;<span>7.2</span></a> shows the observed values of these random variables from a single sample. These are the values available to us for statistical inference about the independence of exposure and disease.</p>
<div id="tbl-2x2observed" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-2x2observed-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7.2: Observed 2x2 table of exposure (<span class="math inline">\(X\)</span>) and disease (<span class="math inline">\(D\)</span>).
</figcaption>
<div aria-describedby="tbl-2x2observed-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: center;"><span class="math inline">\(D = 1\)</span></th>
<th style="text-align: center;"><span class="math inline">\(D = 0\)</span></th>
<th style="text-align: center;">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(X = 1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(a\)</span></td>
<td style="text-align: center;"><span class="math inline">\(b\)</span></td>
<td style="text-align: center;"><span class="math inline">\(r_1\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(X = 0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(c\)</span></td>
<td style="text-align: center;"><span class="math inline">\(d\)</span></td>
<td style="text-align: center;"><span class="math inline">\(r_0\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Total</td>
<td style="text-align: center;"><span class="math inline">\(k_1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(k_0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n\)</span></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<section id="sec-hypergeometric" class="level3" data-number="7.1.1">
<h3 data-number="7.1.1" class="anchored" data-anchor-id="sec-hypergeometric"><span class="header-section-number">7.1.1</span> Hypergeometric distribution*</h3>
<p>Over all possible samples from the population <span class="math inline">\(\Omega\)</span>, the joint distribution of the cell counts <span class="math inline">\(\A\)</span>, <span class="math inline">\(\B\)</span>, <span class="math inline">\(\C\)</span>, and <span class="math inline">\(\D\)</span> in <a href="#tbl-2x2random" class="quarto-xref">Table&nbsp;<span>7.1</span></a> is a <strong>multivariate hypergeometric</strong> distribution. Its probability mass function (PMF) is <span id="eq-mvhypergeometric"><span class="math display">\[
  \Pr(\A = a, \B = b, \C = c, D = d)
  = \frac{\binom{N p_{\A}}{a} \binom{N p_{\B}}{b} \binom{N p_{\C}}{c} \binom{N p_{\D}}{d}}{\binom{N}{n}}
\tag{7.1}\]</span></span> for all <span class="math inline">\(a, b, c, d \geq 0\)</span> such that <span class="math inline">\(a + b + c + d = n\)</span>, where <span class="math display">\[
  \begin{aligned}
    p_{\A}  &amp;= \Pr(X = 1 \text{ and } D = 1) \\
    p_{\B}  &amp;= \Pr(X = 1 \text{ and } D = 0) \\
    p_{\C}  &amp;= \Pr(X = 0 \text{ and } D = 1) \\
    p_{\D}  &amp;= \Pr(X = 0 \text{ and } D = 0)
  \end{aligned}
\]</span> in the underlying population (i.e., where <span class="math inline">\(\Omega\)</span> is the population and we sample a single individual <span class="math inline">\(\omega\)</span> at random). The numerator in <a href="#eq-mvhypergeometric" class="quarto-xref">Equation&nbsp;<span>7.1</span></a> is the number of ways of getting cell counts <span class="math inline">\(\A = a\)</span>, <span class="math inline">\(\B = b\)</span>, <span class="math inline">\(\C = c\)</span>, and <span class="math inline">\(\D = d\)</span> in a sample of size <span class="math inline">\(n\)</span>, and the denominator is the number of samples of size <span class="math inline">\(n\)</span> that can be chosen from our population <span class="math inline">\(\Omega\)</span> of size <span class="math inline">\(N \geq n\)</span>.</p>
<p>The marginal distribution of each cell count is a <strong>hypergeometric distribution</strong>. The PMF of <span class="math inline">\(\A\)</span>, which is the number of individuals who are exposed and have disease (or disease onset), is <span class="math display">\[
  \Pr(\A = a) = \frac{\binom{N p_{\A}}{a} \binom{N (1 - p_{\A})}{n - a}}{\binom{N}{n}}.
\]</span> where <span class="math inline">\(a \geq 0\)</span> and <span class="math inline">\(a \leq n\)</span>. Its mean is <span class="math display">\[
  \E(\A) = n p_{\A},
\]</span> which is identical to the binomial(<span class="math inline">\(n\)</span>, <span class="math inline">\(p_{\A}\)</span>) mean. Its variance is <span class="math display">\[
  \Var(\A) = n p_{\A} (1 - p_{\A}) \frac{N - n}{N - 1},
\]</span> which is smaller than the binomial(<span class="math inline">\(n\)</span>, <span class="math inline">\(p_{\A}\)</span>) variance for all <span class="math inline">\(n &gt; 1\)</span>. The factor <span class="math inline">\((N - n) / (N - 1)\)</span> is called the <em>finite population correction</em>.</p>
<p>The row totals <span class="math inline">\(\R_1\)</span> and <span class="math inline">\(\R_0\)</span> and the column totals <span class="math inline">\(\K_1\)</span> and <span class="math inline">\(\K_0\)</span> from <a href="#tbl-2x2random" class="quarto-xref">Table&nbsp;<span>7.1</span></a> also have hypergeometric distributions. For <span class="math inline">\(\R_1\)</span>, we have <span class="math display">\[
  \Pr(\R_1 = r_1) = \frac{\binom{N \pi}{r_1} \binom{N (1 - \pi)}{n - r_1}}{\binom{N}{n}}
\]</span> where <span class="math inline">\(\pi = \Pr(X = 1)\)</span> is the marginal probability of exposure in the population. For <span class="math inline">\(\K_1\)</span>, we have <span class="math display">\[
  \Pr(\K_1 = k_1) = \frac{\binom{N p}{k_1} \binom{N (1 - p)}{n - k_1}}{\binom{N}{n}}
\]</span> where <span class="math inline">\(p = \Pr(D = 1)\)</span> is the marginal prevalence or risk of disease in the population.</p>
<p>As the population size <span class="math inline">\(N \rightarrow \infty\)</span>, the distribution of <span class="math inline">\(\A\)</span> converges to a binomial(<span class="math inline">\(n\)</span>, <span class="math inline">\(p_{\A}\)</span>) distribution. If <span class="math inline">\(N \rightarrow \infty\)</span> and <span class="math inline">\(n \rightarrow \infty\)</span> such that <span class="math inline">\(n^2 / N \rightarrow 0\)</span>, the distribution of <span class="math display">\[
  \frac{\A - \E(\A)}{\sqrt{\Var(\A)}}
\]</span> converges to the standard normal distribution <span class="math inline">\(N(0, 1)\)</span>. The hypergeometric distributions of the other cell counts and marginal totals also converge to binomial or normal distributions.</p>
</section>
<section id="sec-multinomial" class="level3" data-number="7.1.2">
<h3 data-number="7.1.2" class="anchored" data-anchor-id="sec-multinomial"><span class="header-section-number">7.1.2</span> Multinomial distribution</h3>
<p>If we fix the sample size <span class="math inline">\(n\)</span> and let the population size <span class="math inline">\(N \rightarrow \infty\)</span>, the multivariate hypergeometric distribution converges to the <strong>multinomial distribution</strong>. Its PMF is <span class="math display">\[
  \Pr(\A = a, \B = b, \C = c, \D = d)
  = \frac{n!}{a! b! c! d!} p_{\A}^a p_{\B}^b p_{\C}^c p_{\D}^d.
\]</span> for <span class="math inline">\(a, b, c, d \geq 0\)</span> such that <span class="math inline">\(a + b + c + d = n\)</span>. This PMF is written in terms of four probabilities, but there are only three degrees of freedom because <span class="math inline">\(p_{\A} + p_{\B} + p_{\C} + p_{\D} = 1\)</span>. In the multinomial distribution, the covariance of <span class="math inline">\(\A\)</span> and <span class="math inline">\(\B\)</span> is <span class="math display">\[
  \Cov(\A, \B) = -n p_{\A} p_{\B},
\]</span> and the covariances for the other five pairs of cell counts follow the same pattern. The multinomial approximation to the multivariate hypergeometric distribution and the binomial approximation to the hypergeometric distribution can be used when <span class="math inline">\(N\)</span> is much larger than <span class="math inline">\(n\)</span> (i.e., <span class="math inline">\(N \gg n\)</span>), which is a common situation in epidemiologic studies.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>When the <em>joint</em> distribution of the cell counts is multinomial, the <em>marginal</em> distribution of each cell count is binomial. For example, the distribution of <span class="math inline">\(\A\)</span> is binomial(<span class="math inline">\(n\)</span>, <span class="math inline">\(p_{\A}\)</span>), so its mean is <span class="math inline">\(n p_{\A}\)</span> and its variance is <span class="math inline">\(n p_{\A} (1 - p_{\A})\)</span>. The row and column sums also have binomial distributions. The distribution of <span class="math inline">\(\R_1\)</span> is binomial(<span class="math inline">\(n\)</span>, <span class="math inline">\(\pi\)</span>) where <span class="math display">\[
  \pi = \Pr(X = 1)
\]</span> is the marginal prevalence of exposure. The distribution of <span class="math inline">\(\K_1\)</span> is binomial(<span class="math inline">\(n\)</span>, <span class="math inline">\(p\)</span>) where <span class="math display">\[
  p = \Pr(D = 1)
\]</span> is the marginal prevalence or risk of disease.</p>
</section>
</section>
<section id="sec-2x2independence" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="sec-2x2independence"><span class="header-section-number">7.2</span> Hypothesis tests for independence in a 2x2 table</h2>
<p>When exposure and disease are independent, the multiplication rule for independent events implies that <span class="math display">\[
  \Pr(X = x \text{ and } D = d) = \Pr(X = x) \Pr(D = d)
\]</span> for all possible values <span class="math inline">\(x\)</span> of <span class="math inline">\(X\)</span> and <span class="math inline">\(d\)</span> of <span class="math inline">\(D\)</span>. There are two equivalent ways to express this null hypothesis that will prove useful in thinking about epidemiologic study design: one in terms of conditional risks of disease given exposure and one in terms of conditional prevalences of exposure given disease.</p>
<section id="sec-indep-condprob" class="level3" data-number="7.2.1">
<h3 data-number="7.2.1" class="anchored" data-anchor-id="sec-indep-condprob"><span class="header-section-number">7.2.1</span> Equality of conditional probabilities</h3>
<p>Independence of exposure and disease can be expressed in terms of equality of conditional probabilities of disease (or disease onset) given exposure. Let <span class="math display">\[
  p_1 = \Pr(D = 1 \given{} X = 1)
\]</span> be the risk of disease among the exposed and <span class="math display">\[
  p_0 = \Pr(D = 1 \given{} X = 0)
\]</span> be the prevalence or risk of disease among the unexposed. If exposure and disease are independent, then <span class="math display">\[
  \Pr(D = 1 \given{} X = x)
  = \frac{\Pr(D = 1) \Pr(X = x)}{\Pr(X = x)} = \Pr(D = 1)
\]</span> for <span class="math inline">\(x = 1\)</span> and <span class="math inline">\(x = 0\)</span>. Therefore, <span class="math inline">\(p_1 = p_0\)</span> if exposure and disease are independent. Conversely, suppose <span class="math inline">\(p_1 = p_0\)</span>. By definition of <span class="math inline">\(p_1\)</span> and <span class="math inline">\(p_0\)</span>, <span class="math display">\[
  \Pr(D = 1 \given{} X = 1)
  = \Pr(D = 1 \given{} X = 0).
\]</span> Expanding the conditional probabilities, we get <span class="math display">\[
  \frac{\Pr(D = 1 \text{ and } X = 1)}{\Pr(X = 1)}
  = \frac{\Pr(D = 1 \text{ and } X = 0)}{\Pr(X = 0)}.
\]</span> This can be rewritten as <span class="math display">\[
  \frac{\Pr(D = 1 \vand X = 1)}{\Pr(X = 1)}
  = \frac{\Pr(D = 1) - \Pr(D = 1 \vand X = 1)}{1 - \Pr(X = 1)}.
\]</span> Cross-multiplying the numerators and denominators shows that this equality holds if and only if <span class="math display">\[
  \Pr(D = 1 \vand X = 1) = \Pr(D = 1) \Pr(X = 1).
\]</span> Because <span class="math inline">\(D\)</span> and <span class="math inline">\(X\)</span> are binary, this is establishes that <span class="math inline">\(D\)</span> and <span class="math inline">\(X\)</span> are independent random variables. Therefore, <span class="math inline">\(p_1 = p_0\)</span> implies that exposure and disease are independent. Combining both results shows that <span class="math inline">\(H_0: p_1 = p_0\)</span> is equivalent to the null hypothesis that exposure and disease are independent.</p>
<p>A similar argument applies to the conditional prevalence of exposure given disease status. Let <span class="math display">\[
  \pi_1 = \Pr(X = 1 \given D = 1)
\]</span> be the prevalence of exposure among cases and <span class="math display">\[
  \pi_0 = \Pr(X = 1 \given D = 0)
\]</span> be the prevalence of exposure among controls. The null hypothesis <span class="math inline">\(H_0: \pi_1 = \pi_0\)</span> is equivalent to the null hypothesis that exposure and disease are independent.</p>
</section>
<section id="hypergeometric-chi-squared-test" class="level3" data-number="7.2.2">
<h3 data-number="7.2.2" class="anchored" data-anchor-id="hypergeometric-chi-squared-test"><span class="header-section-number">7.2.2</span> Hypergeometric chi-squared test</h3>
<p>Under the null hypothesis that exposed and disease are independent, we have <span class="math display">\[
  \begin{aligned}
    p_{\A}  &amp;= \Pr(X = 1) \Pr(D = 1) = \pi p, \\
    p_{\B}  &amp;= \Pr(X = 1) \Pr(D = 0) = \pi (1 - p), \\
    p_{\C}  &amp;= \Pr(X = 0) \Pr(D = 1) = (1 - \pi) p, \\
    p_{\D}  &amp;= \Pr(X = 0) \Pr(D = 0) = (1 - \pi) p.
  \end{aligned}
\]</span> The marginal prevalence of exposure <span class="math inline">\(\pi\)</span> and the marginal risk of disease <span class="math inline">\(p\)</span> are both unknown. In a score test of the null hypothesis, these are <em>nuisance parameters</em> that can be replaced by maximum likelihood estimates <span class="citation" data-cites="rao1948large boos2013essential">(<a href="references.html#ref-rao1948large" role="doc-biblioref">Rao 1948</a>; <a href="references.html#ref-boos2013essential" role="doc-biblioref">Boos and Stefanski 2013</a>)</span>. Because <span class="math inline">\(\R_1\)</span> has an approximate binomial(<span class="math inline">\(n\)</span>, <span class="math inline">\(\pi\)</span>) distribution when <span class="math inline">\(N \gg n\)</span>, <span id="eq-2x2hatpi"><span class="math display">\[
  \hat{\pi} = \frac{r_1}{n}.
\tag{7.2}\]</span></span> is the maximum likelihood estimate of <span class="math inline">\(\pi\)</span> based on <a href="#tbl-2x2observed" class="quarto-xref">Table&nbsp;<span>7.2</span></a>. Because <span class="math inline">\(\K_1\)</span> has an approximate binomial(<span class="math inline">\(n\)</span>, <span class="math inline">\(p\)</span>) distribution when <span class="math inline">\(N \gg n\)</span>, <span id="eq-2x2hatp"><span class="math display">\[
  \hat{p} = \frac{k_1}{n}
\tag{7.3}\]</span></span> is the maximum likelihood estimate of <span class="math inline">\(p\)</span> based on <a href="#tbl-2x2observed" class="quarto-xref">Table&nbsp;<span>7.2</span></a>. When we use these maximum likelihood estimates of <span class="math inline">\(\pi\)</span> and <span class="math inline">\(p\)</span> to test independence, we are conditioning on the row and column totals in the observed 2x2 table in <a href="#tbl-2x2observed" class="quarto-xref">Table&nbsp;<span>7.2</span></a>.</p>
<p>Given the margins of a 2x2 table, the entire table is determined by any one of the four cell counts. <a href="#tbl-2x2a" class="quarto-xref">Table&nbsp;<span>7.3</span></a> shows how the cell counts in <a href="#tbl-2x2observed" class="quarto-xref">Table&nbsp;<span>7.2</span></a> are determined by <span class="math inline">\(\A\)</span> and the margins. Because all cell counts must be nonnegative, we must have <span class="math inline">\(\A \geq 0\)</span>, <span class="math inline">\(\A \leq r_1\)</span>, and <span class="math inline">\(\A \leq k_1\)</span>. In the bottom right cell of the <span class="math inline">\(2 \times 2\)</span> table, we must have <span class="math display">\[
  \A - (a - d) \geq 0.
\]</span> Therefore, <span class="math display">\[
  a_\text{min} = \max(0, a - d) \leq \A \leq \min(r_1, k_1) = a_\text{max}.
\]</span> Note that the cells along the diagonal of the <span class="math inline">\(2\times 2\)</span> table (the <span class="math inline">\(\A\)</span> and <span class="math inline">\(\D\)</span> cells) both increase with <span class="math inline">\(\A\)</span>, while the cells off the diagonal (the <span class="math inline">\(\B\)</span> and <span class="math inline">\(\C\)</span> cells) both decrease with <span class="math inline">\(\A\)</span>. Any of the other cells could also determine the entire table given the margins, and constraints on the possible values of <span class="math inline">\(\B\)</span>, <span class="math inline">\(\C\)</span>, and <span class="math inline">\(\D\)</span> given the margins could be found in a similar way.</p>
<div id="tbl-2x2a" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-2x2a-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7.3: 2x2 table determined by <span class="math inline">\(\A\)</span> and the margins.
</figcaption>
<div aria-describedby="tbl-2x2a-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: center;"><span class="math inline">\(D = 1\)</span></th>
<th style="text-align: center;"><span class="math inline">\(D = 0\)</span></th>
<th style="text-align: center;">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(X = 1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\A\)</span></td>
<td style="text-align: center;"><span class="math inline">\(r_1 - \A\)</span></td>
<td style="text-align: center;"><span class="math inline">\(r_1\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(X = 0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(k_1 - \A\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\A - (a - d)\)</span></td>
<td style="text-align: center;"><span class="math inline">\(r_0\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Total</td>
<td style="text-align: center;"><span class="math inline">\(k_1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(k_0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n\)</span></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>The conditional distribution of the cell count <span class="math inline">\(\A\)</span> given the margins of <a href="#tbl-2x2observed" class="quarto-xref">Table&nbsp;<span>7.2</span></a> is hypergeometric. Imagine our sample as a bowl of <span class="math inline">\(n\)</span> marbles, <span class="math inline">\(r_1\)</span> of which are exposed and <span class="math inline">\(r_0\)</span> of which are unexposed. If we randomly choose <span class="math inline">\(k_1\)</span> marbles without replacement to represent the individuals with disease, then <span class="math inline">\(\A\)</span> is the number of exposed marbles in our sample. The probability that we get <span class="math inline">\(a\)</span> exposed marbles and <span class="math inline">\(k_1 - a\)</span> unexposed marbles is <span class="math display">\[
  \Pr(\A = a \given{} \margins)
  = \frac{\binom{r_1}{a} \binom{r_0}{k_1 - a}}{\binom{n}{k_1}}
  = \frac{\binom{r_1}{a} \binom{r_0}{c}}{\binom{n}{k_1}}
  = \frac{r_1!\, r_0!\, k_1!\, k_0!}{a!\, b!\, c!\, d!\, n!}
\]</span> We could also view our sample as a bowl of <span class="math inline">\(n\)</span> marbles of which <span class="math inline">\(k_1\)</span> have disease (or disease onset) and <span class="math inline">\(k_0\)</span> do not. In that case, <span class="math inline">\(A\)</span> is the number of diseased marbles in a sample of <span class="math inline">\(r_1\)</span> marbles that represent exposed individuals and we get exactly the same hypergeometric distribution of <span class="math inline">\(\A\)</span>. The cell counts <span class="math inline">\(\B\)</span>, <span class="math inline">\(\C\)</span>, and <span class="math inline">\(\D\)</span> also have hypergeometric distributions given the margins of the table.</p>
<p>Under the null hypothesis that exposure and disease are independent, the conditional mean of <span class="math inline">\(\A\)</span> given the margins of <a href="#tbl-2x2observed" class="quarto-xref">Table&nbsp;<span>7.2</span></a> is <span class="math display">\[
  \E(\A \given{} \margins) = n \hat{\pi} \hat{p} = \frac{r_1 k_1}{n}
\]</span> and its conditional variance is <span class="math display">\[
  \Var(\A \given{} \margins) = \frac{r_1 r_0 k_1 k_0}{n^2 (n - 1)}.
\]</span> For large <span class="math inline">\(n\)</span>, the hypergeometric distribution is approximately normal so the hypergeometric chi-squared statistic is <span id="eq-chi2H"><span class="math display">\[
  \chisqH = \frac{\big(a - \E(\A \given{} \margins)\big)^2}{\Var(\A \given{} \margins)}
  = \frac{(n - 1) (a d - b c)^2}{r_1 r_0 k_1 k_0}
\tag{7.4}\]</span></span> Under the null hypothesis, <span class="math inline">\(\chisqH \approxsim \chi^2_1\)</span> (i.e., the chi-squared distribution with one degree of freedom). The p-value is <span class="math inline">\(1 - F(\chisqH)\)</span> where <span class="math inline">\(F\)</span> is the cumulative distribution function (CDF) of the <span class="math inline">\(\chi^2_1\)</span> distribution. We reject the null hypothesis at significance level <span class="math inline">\(\alpha\)</span> when <span class="math inline">\(\chisqH\)</span> is sufficiently large that the p-value is less than <span class="math inline">\(\alpha\)</span>. We get exactly the same hypothesis test using <span class="math inline">\(\B\)</span>, <span class="math inline">\(\C\)</span>, or <span class="math inline">\(\D\)</span> instead of <span class="math inline">\(\A\)</span>.</p>
</section>
<section id="pearsons-chi-squared-test" class="level3" data-number="7.2.3">
<h3 data-number="7.2.3" class="anchored" data-anchor-id="pearsons-chi-squared-test"><span class="header-section-number">7.2.3</span> Pearson’s chi-squared test</h3>
<p>A more general approach to testing independence of the rows and columns in a contingency table is <strong>Pearson’s chi-squared test</strong> <span class="citation" data-cites="pearson1900x pearson1922chi">(<a href="references.html#ref-pearson1900x" role="doc-biblioref">Pearson 1900</a>, <a href="references.html#ref-pearson1922chi" role="doc-biblioref">1922</a>)</span>.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> Like the hypergeometric test, Pearson’s chi-squared test conditions on the margins of the table. In a contingency table with <span class="math inline">\(I\)</span> rows and <span class="math inline">\(J\)</span> columns, let <span class="math inline">\(O_{ij}\)</span> be the observed cell count in row <span class="math inline">\(i\)</span> and column <span class="math inline">\(j\)</span>. Let <span class="math inline">\(r_i\)</span> be the total for row <span class="math inline">\(i\)</span> and <span class="math inline">\(k_j\)</span> be the total for column <span class="math inline">\(j\)</span>. Under independence, the expected cell count is <span class="math display">\[
  E_{ij} = \frac{r_i k_j}{n}.
\]</span> Pearson’s chi-squared statistic is <span id="eq-chisqP"><span class="math display">\[
  \chisqP
  = \sum_{i = 1}^I \sum_{j = 1}^J \frac{(O_{ij} - E_{ij})^2}{E_{ij}}
\tag{7.5}\]</span></span> Under the null hypothesis that the variables defining the rows and the colums are independent, <span class="math inline">\(\chisqP\)</span> has a chi-squared distribution with <span class="math inline">\((I - 1) (J - 1)\)</span> degrees of freedom <span class="citation" data-cites="fisher1922interpretation boos2013essential">(<a href="references.html#ref-fisher1922interpretation" role="doc-biblioref">Fisher 1922</a>; <a href="references.html#ref-boos2013essential" role="doc-biblioref">Boos and Stefanski 2013</a>)</span>. In any contingency table, Pearson’s chi-squared test is the score test of the null hypothesis that the rows and columns are independent based on a multinomial model (see <a href="#sec-multinomial" class="quarto-xref"><span>Section 7.1.2</span></a>) for the joint distribution of the cell counts <span class="citation" data-cites="boos2013essential">(<a href="references.html#ref-boos2013essential" role="doc-biblioref">Boos and Stefanski 2013</a>)</span>.</p>
<p>In <a href="#tbl-2x2observed" class="quarto-xref">Table&nbsp;<span>7.2</span></a>, we have <span class="math inline">\(I = J = 2\)</span> with <span class="math inline">\(O_{11} = a\)</span>, <span class="math inline">\(O_{12} = b\)</span>, <span class="math inline">\(O_{21} = c\)</span>, and <span class="math inline">\(O_{22} = d\)</span>. Using the multivariate hypergeometric distribution or its multinomial approximation, we have the following estimated expected cell counts under the null hypothesis that exposure and disease are independent: <span id="eq-Eindep"><span class="math display">\[
  \begin{aligned}
    \E_{11} = \E(\A \given \margins)
      &amp;= n \hat{\pi} \hat{p}        = \frac{r_1 k_1}{n} \\
    \E_{12} = \E(\B \given \margins)
      &amp;= n \hat{\pi} (1 - \hat{p})  = \frac{r_1 k_0}{n} \\
    \E_{21} = \E(\C \given \margins)
      &amp;= n (1 - \hat{\pi}) \hat{p}  = \frac{r_0 k_1}{n} \\
    \E_{22} = \E(\D \given \margins)
      &amp;= n (1 - \hat{\pi}) (1 - \hat{p}) = \frac{r_0 k_0}{n}.
  \end{aligned}
\tag{7.6}\]</span></span> As in the hypergeometric chi-squared test, we are conditioning on the margins of the table because we are using the maximum likelihood estimates of <span class="math inline">\(\pi\)</span> (the prevalence of exposure) and <span class="math inline">\(p\)</span> (the risk of disease). When the dust settles in <a href="#eq-chisqP" class="quarto-xref">Equation&nbsp;<span>7.5</span></a>, we get <span id="eq-chisqP2"><span class="math display">\[
  \chisqP = \frac{n (ad - bc)^2}{r_1 r_0 k_1 k_0} = \frac{n}{n - 1} \chisqH.
\tag{7.7}\]</span></span> When exposure and disease are independent, <span class="math inline">\(\chisqP\)</span> has a chi-squared distribution with <span class="math inline">\((2 - 1) (2 - 1) = 1\)</span> degrees of freedom. The p-value is <span class="math inline">\(1 - F(\chisqP)\)</span> where <span class="math inline">\(F\)</span> is the CDF of the <span class="math inline">\(\chi^2_1\)</span> distribution, and we reject the null hypothesis at significance level <span class="math inline">\(\alpha\)</span> when <span class="math inline">\(\chisqP\)</span> is sufficiently large that the p-value is less than <span class="math inline">\(\alpha\)</span>.</p>
<p>The chi-squared approximation to the distribution of <span class="math inline">\(\chisqP\)</span> is generally considered acceptable if the minimum expected cell count is greater than or equal to five, and it is likely to be accurate whenever the average expected cell count is greater than or equal to <span class="math inline">\(7.5\)</span> <span class="citation" data-cites="roscoe1971investigation">(<a href="references.html#ref-roscoe1971investigation" role="doc-biblioref">Roscoe and Byars 1971</a>)</span>, which is equivalent to <span class="math inline">\(n \geq 30\)</span> for a 2x2 table.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> Because <span class="math inline">\(\chisqH &lt; \chisqP\)</span>, the hypergeometric chi-squared test is slightly more conservative than Pearson’s chi-squared test in the sense that it is less likely to reject the null hypothesis of independence. For large <span class="math inline">\(n\)</span>, there is no practical difference.</p>
</section>
<section id="small-samples-and-exact-tests" class="level3" data-number="7.2.4">
<h3 data-number="7.2.4" class="anchored" data-anchor-id="small-samples-and-exact-tests"><span class="header-section-number">7.2.4</span> Small samples and exact tests*</h3>
<p>In small samples, the hypergeometric distribution can be used to calculate “exact” p-values. For two-sided alternative hypotheses, this leads to <strong>Fisher’s exact test</strong> <span class="citation" data-cites="fisher1935logic irwin1935tests">(<a href="references.html#ref-fisher1935logic" role="doc-biblioref">Fisher 1935</a>; <a href="references.html#ref-irwin1935tests" role="doc-biblioref">Irwin et al. 1935</a>)</span> or <strong>Blaker’s exact test</strong> <span class="citation" data-cites="blaker2000confidence">(<a href="references.html#ref-blaker2000confidence" role="doc-biblioref">Blaker 2000</a>)</span>. These use the hypergeometric PMF to calculate a p-value for the null hypothesis of independent rows and columns. These tests differ slightly in the way that they define the tails of the distribution of <span class="math inline">\(\A\)</span>, and there are two versions of Fisher’s exact test.</p>
<p>The <em>minimum likelihood</em> Fisher’s exact test defines the p-value as the sum of the probabilities of all possible <span class="math inline">\(\mathcal{a}\)</span> such that <span class="math inline">\(\Pr(A = \mathcal{a} \given{} \margins) \leq \Pr(\A = a \given{} \margins)\)</span>. The simpler but slightly less powerful <em>central</em> Fisher’s exact test defines the p-value as twice the twice the minimum of the tail probabilities <span class="math inline">\(\Pr(\A \leq a \given{} \margins)\)</span> and <span class="math inline">\(\Pr(A \geq a \given{} \margins)\)</span>.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<p>Blaker’s exact test defines the p-value as the minumum tail probability plus the probability of an opposite tail defined so that its probability is less than or equal to that of the smaller tail. For example: If the smaller tail is <span class="math inline">\(\A \leq a\)</span>, then the p-value is <span class="math display">\[
  \Pr(A \leq a \given{} \margins) + \sum_{a' = a_\text{opp}}^{a_\text{max}} \Pr(A = a' \given{} \margins)
\]</span> where <span class="math inline">\(a_\text{opp}\)</span> is chosen so that the sum in the second term is less than or equal to <span class="math inline">\(\Pr(A \leq a \given{} \margins)\)</span>. Blaker’s test is sometimes more powerful and never less powerful than both versions of Fisher’s exact test <span class="citation" data-cites="blaker2000confidence fay2010confidence">(<a href="references.html#ref-blaker2000confidence" role="doc-biblioref">Blaker 2000</a>; <a href="references.html#ref-fay2010confidence" role="doc-biblioref">Fay 2010</a>)</span>.</p>
<p>These tests are ``exact’’ in the sense that they reject a true null hypothesis with probability less than or equal to the nominal significance level <span class="math inline">\(\alpha\)</span>. However, they are often overly conservative in that the true significance level (i.e., the actual probability of rejecting the null hypothesis when it is true) can be substantially less than <span class="math inline">\(\alpha\)</span>. Using mid-p values mitigates this problem, ensuring that the true significance level stays closer to <span class="math inline">\(\alpha\)</span>. The price of this is that the true significance level of the test can be slightly greater than <span class="math inline">\(\alpha\)</span>, so the mid-p tests are no longer “exact” <span class="citation" data-cites="lancaster1961significance routledge1992resolving agresti2012categorical">(<a href="references.html#ref-lancaster1961significance" role="doc-biblioref">Lancaster 1961</a>; <a href="references.html#ref-routledge1992resolving" role="doc-biblioref">Routledge 1992</a>; <a href="references.html#ref-agresti2012categorical" role="doc-biblioref">Agresti 2013</a>)</span>.</p>
</section>
</section>
<section id="cohort-studies" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="cohort-studies"><span class="header-section-number">7.3</span> Cohort studies</h2>
<p>Random sampling from the population is not the most efficient way to detect a departure from independence of exposure and disease. By rearranging the Pearson chi-squared statistic <span class="math inline">\(\chisqP\)</span> from equation <a href="#eq-chisqP2" class="quarto-xref">Equation&nbsp;<span>7.7</span></a>, we can identify two strategies for generating a more powerful test. One is to select participants by exposure, which leads to the <strong>cohort study</strong> design. The other is to select participants by disease, which leads to the <strong>case-control</strong> study design. In both cases, a balanced study design is optimal (or near-optimal) and Pearson’s chi-squared test is the score test of the null hypothesis that exposure and disease are independent. If participation in the study involves any cost, risk, or inconvenience, then maximizing the power of the study for a given number of participants is an important ethical consideration because an inefficient study will place an unnecessary burden on some participants.</p>
<section id="selection-by-exposure" class="level3" data-number="7.3.1">
<h3 data-number="7.3.1" class="anchored" data-anchor-id="selection-by-exposure"><span class="header-section-number">7.3.1</span> Selection by exposure</h3>
<p>The Pearson chi-squared statistic <span class="math inline">\(\chisqP\)</span> from <a href="#eq-chisqP" class="quarto-xref">Equation&nbsp;<span>7.5</span></a> can be rewritten in terms of the risks of disease in exposed and unexposed individuals. As above, let <span class="math inline">\(p_1\)</span> be the risk of disease in the exposed and <span class="math inline">\(p_0\)</span> be the risk of disease in the unexposed. In <a href="#tbl-2x2observed" class="quarto-xref">Table&nbsp;<span>7.2</span></a>, their maximum likelihood estimates are <span class="math inline">\(\hat{p}_1 = a / r_1\)</span> and <span class="math inline">\(\hat{p}_0 = c / r_0\)</span>. The maximum likelihood estimate of <span class="math inline">\(p_1 - p_0\)</span> is <span id="eq-cohort-num"><span class="math display">\[
  \hat{p}_1 - \hat{p}_0
  = \frac{a}{a + b} - \frac{c}{c + d}
  = \frac{a d - b c}{(a + b) (c + d)}
  = \frac{a d - b c}{r_1 r_0}.
\tag{7.8}\]</span></span> <a href="#sec-indep-condprob" class="quarto-xref"><span>Section 7.2.1</span></a> showed that the null hypothesis that exposure and disease are independent is equivalent to <span class="math inline">\(H_0: p_1 = p_0 = p\)</span> where <span class="math inline">\(p\)</span> is the marginal risk of disease.</p>
<p>When <span class="math inline">\(n \ll N\)</span> and the null hypothesis is true, <span class="math inline">\(\A\)</span> has an approximate binomial(<span class="math inline">\(r_1\)</span>, <span class="math inline">\(p\)</span>) conditional distribution, <span class="math inline">\(\C\)</span> has an approximate binomial(<span class="math inline">\(r_0\)</span>, <span class="math inline">\(p\)</span>) conditional distribution, and they are conditionally independent given the row sums <span class="math inline">\(r_1\)</span> and <span class="math inline">\(r_0\)</span>. Thus, the large-sample variance of <span class="math inline">\(\hat{p}_1 - \hat{p}_0\)</span> under the null is approximately <span id="eq-cohort-den"><span class="math display">\[
  \Var_0(\hat{p}_1 - \hat{p}_0)
  = p (1 - p) \bigg(\frac{1}{r_1} + \frac{1}{r_0}\bigg)
  = p (1 - p) \frac{n}{r_1 r_0}
\tag{7.9}\]</span></span> where we used <span class="math inline">\(n = r_1 + r_0\)</span>. Replacing the unknown <span class="math inline">\(p\)</span> with its maximum likelihood estimate <span class="math inline">\(\hat{p} = k_1 / n\)</span>, we get the estimated null variance <span id="eq-chisqP-den"><span class="math display">\[
  \hat{\Var}_0(\hat{p}_1 - \hat{p}_0)
  = \hat{p} (1 - \hat{p}) \frac{n}{r_1 r_0}
  = \frac{k_1 k_0}{r_1 r_0 n}
\tag{7.10}\]</span></span> where we used <span class="math inline">\(1 - \hat{p} = k_0 / n\)</span>. Combining <a href="#eq-cohort-num" class="quarto-xref">Equation&nbsp;<span>7.8</span></a> and <a href="#eq-cohort-den" class="quarto-xref">Equation&nbsp;<span>7.9</span></a>, we get <span class="math display">\[
  \frac{(\hat{p}_1 - \hat{p}_0)^2}{\hat{p} (1 - \hat{p}) \Big(\frac{1}{r_1} + \frac{1}{r_0}\Big)}
  = \frac{n (a d - b c)^2}{r_1 r_0 k_1 k_0}
  = \chisqP
\]</span> (see <a href="#eq-chisqP2" class="quarto-xref">Equation&nbsp;<span>7.7</span></a>). Let <span class="math inline">\(\varphi\)</span> be the proportion of our sample that is exposed, so <span class="math inline">\(r_1 = \varphi n\)</span> and <span class="math inline">\(r_0 = (1 - \varphi) n\)</span>. As <span class="math inline">\(n \rightarrow \infty\)</span>, we have <span class="math inline">\(r_1 \rightarrow \infty\)</span> and <span class="math inline">\(r_0 \rightarrow \infty\)</span>. The law of large numbers (LLN) guarantees that <span class="math inline">\(\hat{p}_1 \rightarrow p_1\)</span>, <span class="math inline">\(\hat{p}_0 \rightarrow p_0\)</span>, and <span class="math display">\[
    \hat{p} \rightarrow p_\varphi = \varphi p_1 + (1 - \varphi) p_0.
\]</span> In large samples, <span id="eq-chisqP-largecohort"><span class="math display">\[
  \chisqP
  \approx \frac{(p_1 - p_0)^2}{p_\varphi (1 - p_\varphi) \Big(\frac{1}{r_1} + \frac{1}{r_0}\Big)}
  = \frac{(p_1 - p_0)^2}{p_\varphi (1 - p_\varphi) \frac{1}{\phi (1 - \phi) n}}
\tag{7.11}\]</span></span> The numerator of <a href="#eq-chisqP-largecohort" class="quarto-xref">Equation&nbsp;<span>7.11</span></a> is fixed, but the denominator depends on <span class="math inline">\(r_1\)</span>, <span class="math inline">\(r_0\)</span>, and <span class="math inline">\(\varphi = r_1 / n\)</span>. By sampling according to exposure, we can choose <span class="math inline">\(r_1\)</span> and <span class="math inline">\(r_0\)</span> to increase the power of the Pearson chi-squared test for a fixed total number of participants.</p>
</section>
<section id="score-test-for-independence-in-a-cohort-study" class="level3" data-number="7.3.2">
<h3 data-number="7.3.2" class="anchored" data-anchor-id="score-test-for-independence-in-a-cohort-study"><span class="header-section-number">7.3.2</span> Score test for independence in a cohort study*</h3>
<p>We need to make sure that sampling by exposure does not change the score test of the null hypothesis that exposure and disease are independent. Using a binomial(<span class="math inline">\(r_1\)</span>, <span class="math inline">\(p_1\)</span>) distribution for the number of individuals with disease the exposed group and a binomial(<span class="math inline">\(r_0\)</span>, <span class="math inline">\(p_0\)</span>) distribution for the number of individuals with disease in the unexposed group, the log likelihood is <span class="math display">\[
  \ell(p_1, p_0) = \A \ln p_1 + \B \ln(1 - p_1) + \C \ln p_0 + \D \ln(1 - p_0),
\]</span> where we have dropped terms that do not depend on <span class="math inline">\(p_1\)</span> or <span class="math inline">\(p_0\)</span>. In order to calculate the expected information for the score test, we view the log likelihood as a random variable whose value will be determined by the realized values <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, <span class="math inline">\(c\)</span>, and <span class="math inline">\(d\)</span> of the random variables <span class="math inline">\(\A\)</span>, <span class="math inline">\(\B\)</span>, <span class="math inline">\(\C\)</span>, and <span class="math inline">\(\D\)</span>. The score function and the information function will also be treated as random variables.</p>
<p>Because <span class="math inline">\(\ell(p_1, p_0)\)</span> depends on two parameters, the score function is a column vector of length two: <span class="math display">\[
  U(p_1, p_0)
  = \begin{pmatrix}
      \frac{\partial}{\partial p_1} \ell(p_1, p_0) \\[5pt]
      \frac{\partial}{\partial p_0} \ell(p_1, p_0)
    \end{pmatrix}
  = \begin{pmatrix}
      \frac{\A}{p_1} - \frac{\B}{1 - p_1} \\[5pt]
      \frac{\C}{p_0} - \frac{\D}{1 - p_0}
    \end{pmatrix}.
\]</span> The information <span class="math inline">\(I(p_1, p_0)\)</span> is a 2x2 matrix <span class="math display">\[
  \begin{bmatrix}
    \frac{\partial^2}{\partial p_1^2} \ell(p_1, p_0)
      &amp; \frac{\partial^2}{\partial p_1 \partial p_0} \ell(p_1, p_0) \\[5pt]
    \frac{\partial^2}{\partial p_0 \partial p_1} \ell(p_1, p_0)
      &amp; \frac{\partial^2}{\partial p_0^2} \ell(p_1, p_0)
  \end{bmatrix} \\
  = \begin{bmatrix}
      \frac{\A}{p_1^2} + \frac{\B}{(1 - p_1)^2} &amp; 0 \\
      0 &amp; \frac{\C}{p_0^2} + \frac{\D}{(1 - p_0)^2}
    \end{bmatrix}.
\]</span> The realized value of <span class="math inline">\(U(p_1, p_0)\)</span> and the observed information <span class="math inline">\(I(p_1, p_0)\)</span> are obtained by replacing the random variables <span class="math inline">\(\A\)</span>, <span class="math inline">\(\B\)</span>, <span class="math inline">\(\C\)</span>, and <span class="math inline">\(\D\)</span> with their realized values <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, <span class="math inline">\(c\)</span>, and <span class="math inline">\(d\)</span>.</p>
<p>The score statistic is calculated under the null hypothesis <span class="math inline">\(H_0: p_1 = p_0 = p\)</span>, and we use the expected information <span class="citation" data-cites="freedman2007can">(<a href="references.html#ref-freedman2007can" role="doc-biblioref">Freedman 2007</a>)</span>. Let <span class="math inline">\(\E_0(Y)\)</span> be the expected value of a random variable <span class="math inline">\(Y\)</span> calculated under <span class="math inline">\(H_0\)</span>. Then <span class="math inline">\(\E_0(\A) = n_1 p\)</span>, <span class="math inline">\(\E_0(\B) = n_1 (1 - p)\)</span>, <span class="math inline">\(\E_0(\C) = n_0 p\)</span>, and <span class="math inline">\(\E_0(\D) = n_0 (1 - p)\)</span>, so the expected information under <span class="math inline">\(H_0\)</span> is <span class="math display">\[
    \mathcal{I}(p, p)
    = \E_0[I(p, p)]
    = \begin{bmatrix}
        \frac{n_1}{p} + \frac{n_1}{1 - p} &amp; 0 \\
        0 &amp; \frac{n_0}{p} + \frac{n_0}{1 - p}
    \end{bmatrix}.
\]</span> Both <span class="math inline">\(U(p, p)\)</span> and <span class="math inline">\(\mathcal{I}(p, p)\)</span> depend on the unknown <span class="math inline">\(p\)</span>, which we replace with its maximum likelihood estimate <span class="math inline">\(\hat{p} = k_1 / n\)</span>. This gives us the score <span class="math display">\[
  U(\hat{p}, \hat{p})
  = \begin{pmatrix}
    \frac{a}{\hat{p}} - \frac{b}{1 - \hat{p}} \\[5pt]
    \frac{c}{\hat{p}} - \frac{d}{1 - \hat{p}}
  \end{pmatrix}
  = \begin{pmatrix}
    \frac{n a}{k_1} - \frac{n b}{k_0} \\[5pt]
    \frac{n c}{k_1} - \frac{n d}{k_0}
  \end{pmatrix}
  = \begin{pmatrix}
      \frac{n (a d - b c)}{k_1 k_0} \\[5pt]
      - \frac{n (a d - b c)}{k_1 k_0}
    \end{pmatrix}.
\]</span> where we used <span class="math inline">\(k_1 = a + c\)</span> and <span class="math inline">\(k_0 = b + d\)</span>. The expected information at <span class="math inline">\(p = \hat{p}\)</span> is <span class="math display">\[
  \mathcal{I}(\hat{p}, \hat{p})
  = \begin{bmatrix}
      \frac{r_1 n^2}{k_1 k_0} &amp; 0 \\
      0                       &amp; \frac{r_0 n^2}{k_1 k_0}
    \end{bmatrix}
  \;\Rightarrow\;
  \mathcal{I}^{\,-1}(\hat{p}, \hat{p})
  = \begin{bmatrix}
      \frac{k_1 k_0}{r_1 n^2} &amp; 0 \\
      0                       &amp; \frac{k_1 k_0}{r_0 n^2}
    \end{bmatrix}
\]</span> where we used <span class="math inline">\(n_1 = r_1\)</span> and <span class="math inline">\(n_0 = r_0\)</span>. The score statistic is <span class="math display">\[
  U(\hat{p}, \hat{p})^\transpose \mathcal{I}(\hat{p}, \hat{p})^{-1} U(\hat{p}, \hat{p})
  = \frac{n (a d - b c)^2}{r_1 r_0 k_1 k_0}
  = \chisqP,
\]</span> from <a href="#eq-chisqP2" class="quarto-xref">Equation&nbsp;<span>7.7</span></a>. Because <span class="math inline">\(H_0\)</span> reduces the degrees of freedom from two (<span class="math inline">\(p_1\)</span> and <span class="math inline">\(p_0\)</span>) to one (<span class="math inline">\(p_1 = p_0 = p\)</span>), <span class="math inline">\(\chisqP\)</span> has an asymptotic <span class="math inline">\(\chi^2\)</span> distribution with <span class="math inline">\(2 - 1 = 1\)</span> degree of freedom under the null. Therefore, Pearson’s chi-squared test is the score test of independence of exposure and disease in a cohort study. The row sums <span class="math inline">\(r_1\)</span> and <span class="math inline">\(r_0\)</span> are fixed by design, and we condition on the column sums <span class="math inline">\(k_1\)</span> because we use the maximum likelihood estimate <span class="math inline">\(\hat{p} = k_1 / n\)</span> of the risk of disease under <span class="math inline">\(H_0\)</span>.</p>
<p>When it uses the expected information, the score test does not depend on the parameterization of the model for <span class="math inline">\(p_1\)</span> and <span class="math inline">\(p_0\)</span> <span class="citation" data-cites="boos2013essential">(<a href="references.html#ref-boos2013essential" role="doc-biblioref">Boos and Stefanski 2013</a>)</span>. We get the same score statistic <span class="math inline">\(\chisqP\)</span> and the same <span class="math inline">\(\chi^2_1\)</span> distribution under the null even if the model uses transformations of <span class="math inline">\(p_1\)</span> and <span class="math inline">\(p_0\)</span> (e.g., log or logit) or if it is parameterized in terms of the <em>risk difference</em> <span class="math inline">\(\RD = p_1 - p_0\)</span>, the <em>risk ratio</em> <span class="math inline">\(\RR = p_1 / p_0\)</span>, or the <em>odds ratio</em> <span class="math inline">\(\OR = \odds(p_1) / \odds(p_0)\)</span> where <span class="math inline">\(\odds(p) = p / (1 - p)\)</span>. All roads lead to the same score test of the null hypothesis that exposure and disease are independent, which corresponds to <span class="math inline">\(\RD = 0\)</span> and <span class="math inline">\(\RR = \OR = 1\)</span>.</p>
</section>
<section id="sec-optim-cohort" class="level3" data-number="7.3.3">
<h3 data-number="7.3.3" class="anchored" data-anchor-id="sec-optim-cohort"><span class="header-section-number">7.3.3</span> Optimal sampling by exposure</h3>
<p>Having established that <span class="math inline">\(\chisqP\)</span> is the score statistic for testing the independence of exposure and disease in a cohort study, we can choose <span class="math inline">\(r_1\)</span> and <span class="math inline">\(r_0\)</span> to maximize the power of the test for a given number of participants <span class="math inline">\(n = r_1 + r_0\)</span>. The value of the chi-squared statistic in <a href="#eq-chisqP-largecohort" class="quarto-xref">Equation&nbsp;<span>7.11</span></a> depends on <span class="math inline">\(r_1\)</span> and <span class="math inline">\(r_0\)</span> only in the denominator, so we can maximize the statistic by minimizing its denominator. Writing the denominator of <a href="#eq-chisqP-den" class="quarto-xref">Equation&nbsp;<span>7.10</span></a> in terms of <span class="math inline">\(p_1\)</span>, <span class="math inline">\(p_0\)</span>, and <span class="math inline">\(\varphi = r_1 / n\)</span> of the sample that is exposed and simplifying gives us <span id="eq-denom-phi"><span class="math display">\[
  \frac{n p (1 - p)}{r_1 r_0}
  = \frac{\varphi}{1 - \varphi} p_1 (1 - p_1) + \frac{1 - \varphi}{\varphi} p_0 (1 - p_0) + C(p_1, p_0)
\tag{7.12}\]</span></span> where <span class="math inline">\(C(p_1, p_0) = p_1 (1 - p_0) + p_0 (1 - p_1)\)</span> does not depend on <span class="math inline">\(\varphi\)</span>. The derivative of this with respect to <span class="math inline">\(\varphi\)</span> is <span id="eq-deriv-phi"><span class="math display">\[
  \frac{\dif}{\dif \varphi} \frac{n p (1 - p)}{r_1 r_0}
  = \frac{p_1 (1 - p_1)}{(1 - \varphi)^2} - \frac{p_0 (1 - p_0)}{\varphi^2},
\tag{7.13}\]</span></span> which equals zero when <span id="eq-minphi"><span class="math display">\[
  \frac{\varphi}{1 - \varphi} = \sqrt{\frac{p_0 (1 - p_0)}{p_1 (1 - p_1)}}.
\tag{7.14}\]</span></span> To see that this is a minimum and not a maximum, notice that the function in equation <a href="#eq-denom-phi" class="quarto-xref">Equation&nbsp;<span>7.12</span></a> takes large values for <span class="math inline">\(\varphi\)</span> near one when <span class="math inline">\(p_1 (1 - p_1) &gt; 0\)</span> and for <span class="math inline">\(\varphi\)</span> near zero when <span class="math inline">\(p_0 (1 - p_0) &gt; 0\)</span>. It also has a positive second derivative with respect to <span class="math inline">\(\varphi\)</span>.</p>
<p>Solving for <span class="math inline">\(\varphi\)</span> in <a href="#eq-minphi" class="quarto-xref">Equation&nbsp;<span>7.14</span></a> shows that a proportion exposed of <span id="eq-optimphi"><span class="math display">\[
  \varphi^*
  = \frac{1}{1 + \sqrt{\frac{p_1 (1 - p_1)}{p_0 (1 - p_0)}}}.
\tag{7.15}\]</span></span> maximizes the expected value of the Pearson chi-squared statistic <span class="math inline">\(\chisqP\)</span> for a given <span class="math inline">\(n\)</span> <span class="citation" data-cites="walter1977determination">(<a href="references.html#ref-walter1977determination" role="doc-biblioref">Walter 1977</a>)</span>. The expression inside the square root is the variance of a Bernoulli(<span class="math inline">\(p_1\)</span>) random variable divided by the variance of a Bernoulli(<span class="math inline">\(p_0\)</span>) random variable. <a href="#fig-optim-phi" class="quarto-xref">Figure&nbsp;<span>7.1</span></a> shows how <span class="math inline">\(\varphi^*\)</span> depends on this variance ratio. When <span class="math inline">\(p_1 \approx p_0\)</span>, the Bernoulli variance ratio is approximately one and <span class="math inline">\(\varphi^* \approx 0.5\)</span>.</p>
<div class="cell">
<div class="code-with-filename">
<details class="code-fold">
<summary>Code</summary>
<div class="code-with-filename-file">
<pre><strong>optim-phi.R</strong></pre>
</div>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="do">## Optimal proportion exposed in a cohort study</span></span>
<span id="cb1-2"><a href="#cb1-2"></a></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="co"># plot of optimal phi as a function of the Bernoulli variance ratio</span></span>
<span id="cb1-4"><a href="#cb1-4"></a>logvratio <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb1-5"><a href="#cb1-5"></a>phi <span class="ot">&lt;-</span> <span class="cf">function</span>(v) <span class="dv">1</span> <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">sqrt</span>(v))</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="fu">plot</span>(logvratio, <span class="fu">phi</span>(<span class="fu">exp</span>(logvratio)), <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">xaxt =</span> <span class="st">"n"</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb1-7"><a href="#cb1-7"></a>     <span class="at">xlab =</span> <span class="st">"Bernoulli variance ratio (log scale)"</span>,</span>
<span id="cb1-8"><a href="#cb1-8"></a>     <span class="at">ylab =</span> <span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">"Optimal proportion exposed or cases ("</span>, phi, <span class="st">"*)"</span>)))</span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="fu">axis</span>(<span class="dv">1</span>, <span class="at">at =</span> <span class="fu">log</span>(<span class="fu">c</span>(<span class="dv">1</span> <span class="sc">/</span> <span class="fu">c</span>(<span class="dv">16</span>, <span class="dv">8</span>, <span class="dv">4</span>, <span class="dv">2</span>), <span class="dv">1</span>, <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">8</span>, <span class="dv">16</span>))),</span>
<span id="cb1-10"><a href="#cb1-10"></a>     <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"1/16"</span>, <span class="st">"1/8"</span>, <span class="st">"1/4"</span>, <span class="st">"1/2"</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">8</span>, <span class="dv">16</span>))</span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="fu">grid</span>()</span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">"darkgray"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell-output-display">
<div id="fig-optim-phi" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-optim-phi-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="studydesign_files/figure-html/fig-optim-phi-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;7.1: The optimal proportion exposed \varphi^* in a cohort study as a function of the Bernoulli variance ratio p_1 (1 - p_1) / (p_0 (1 - p_0)). In a case-control study, \varphi^* represents the optimal proportion of the sample who are cases and the Bernoulli variance ratio is \pi_1 (1 - \pi_1) / (\pi_0 (1 - \pi_0)). There is a dark gray horizontal line at \varphi = 0.5, which represents a balanced study."><img src="studydesign_files/figure-html/fig-optim-phi-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-optim-phi-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.1: The optimal proportion exposed <span class="math inline">\(\varphi^*\)</span> in a cohort study as a function of the Bernoulli variance ratio <span class="math inline">\(p_1 (1 - p_1) / (p_0 (1 - p_0))\)</span>. In a case-control study, <span class="math inline">\(\varphi^*\)</span> represents the optimal proportion of the sample who are cases and the Bernoulli variance ratio is <span class="math inline">\(\pi_1 (1 - \pi_1) / (\pi_0 (1 - \pi_0))\)</span>. There is a dark gray horizontal line at <span class="math inline">\(\varphi = 0.5\)</span>, which represents a balanced study.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The “optimal” proportion exposed <span class="math inline">\(\varphi^*\)</span> from <a href="#eq-optimphi" class="quarto-xref">Equation&nbsp;<span>7.15</span></a> is based on maximizing the value of <span class="math inline">\(\chisqP\)</span> in large samples. For a given sample size, the power of the test is actually determined by the distribution of possible values of <span class="math inline">\(\chisqP\)</span>, so the maximum power can occur at a value of <span class="math inline">\(\varphi\)</span> slightly different from <span class="math inline">\(\varphi^*\)</span>. <a href="#fig-chisq-power" class="quarto-xref">Figure&nbsp;<span>7.2</span></a> shows the power achieved by Pearson’s chi-squared test at several combinations of <span class="math inline">\(p_1\)</span>, <span class="math inline">\(p_0\)</span>, and <span class="math inline">\(n\)</span>. In all cases, the power at <span class="math inline">\(\varphi = 0.5\)</span> is close to that at <span class="math inline">\(\varphi^*\)</span>. In several cases, the power at <span class="math inline">\(\varphi = 0.5\)</span> exceeds that at <span class="math inline">\(\varphi^*\)</span>. If we have strong enough prior information about <span class="math inline">\(p_1\)</span> and <span class="math inline">\(p_0\)</span> to justify an imbalanced study design, the value of testing the null hypothesis that <span class="math inline">\(p_1 = p_0\)</span> is questionable. Without such prior information, a balanced study is a safe bet to be optimal or near-optimal in terms of the power to detect an association between exposure and disease <span class="citation" data-cites="walter1977determination">(<a href="references.html#ref-walter1977determination" role="doc-biblioref">Walter 1977</a>)</span>.</p>
<div id="fig-chisq-power" class="lightbox quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-chisq-power-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./images/chisq-power.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;7.2: The power of the Pearson chi-squared test from a cohort study as a function of the proportion of the sample exposed (\varphi) at several combinations of p_1 and p_0 for n = 400 (solid), n = 200 (dashed), and n = 100 (dotted). There is a dark gray solid line at \varphi = 0.5, representing a balanced study, and a dark gray dashed line at \varphi^* from Equation&nbsp;eq-optimphi. The same power is achieved by a case control study where \pi_1 replaces p_1, \pi_0 replaces p_0, and \varphi is the proportion of the sample who are cases."><img src="./images/chisq-power.png" class="img-fluid figure-img" style="width:90.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-chisq-power-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.2: The power of the Pearson chi-squared test from a cohort study as a function of the proportion of the sample exposed (<span class="math inline">\(\varphi\)</span>) at several combinations of <span class="math inline">\(p_1\)</span> and <span class="math inline">\(p_0\)</span> for <span class="math inline">\(n = 400\)</span> (solid), <span class="math inline">\(n = 200\)</span> (dashed), and <span class="math inline">\(n = 100\)</span> (dotted). There is a dark gray solid line at <span class="math inline">\(\varphi = 0.5\)</span>, representing a balanced study, and a dark gray dashed line at <span class="math inline">\(\varphi^*\)</span> from <a href="#eq-optimphi" class="quarto-xref">Equation&nbsp;<span>7.15</span></a>. The same power is achieved by a case control study where <span class="math inline">\(\pi_1\)</span> replaces <span class="math inline">\(p_1\)</span>, <span class="math inline">\(\pi_0\)</span> replaces <span class="math inline">\(p_0\)</span>, and <span class="math inline">\(\varphi\)</span> is the proportion of the sample who are cases.
</figcaption>
</figure>
</div>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" aria-current="page">R</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>chisq-power.R</strong></pre>
</div>
<div class="sourceCode" id="cb2" data-filename="chisq-power.R"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a><span class="do">## Actual power of a Pearson chi-squared test</span></span>
<span id="cb2-2"><a href="#cb2-2"></a></span>
<span id="cb2-3"><a href="#cb2-3"></a><span class="co"># calculate Pearson chi-squared test power</span></span>
<span id="cb2-4"><a href="#cb2-4"></a><span class="co"># This can take a few minutes to run with large n.</span></span>
<span id="cb2-5"><a href="#cb2-5"></a>powers <span class="ot">&lt;-</span> <span class="cf">function</span>(p1, p0, n, <span class="at">level =</span> <span class="fl">0.95</span>) {</span>
<span id="cb2-6"><a href="#cb2-6"></a>  chisq_alpha <span class="ot">&lt;-</span> <span class="fu">qchisq</span>(level, <span class="at">df =</span> <span class="dv">1</span>)</span>
<span id="cb2-7"><a href="#cb2-7"></a>  htest <span class="ot">&lt;-</span> <span class="cf">function</span>(r1) {</span>
<span id="cb2-8"><a href="#cb2-8"></a>    r0 <span class="ot">&lt;-</span> n <span class="sc">-</span> r1</span>
<span id="cb2-9"><a href="#cb2-9"></a>    joint_dbinom <span class="ot">&lt;-</span> <span class="fu">outer</span>(<span class="dv">0</span><span class="sc">:</span>r1, <span class="dv">0</span><span class="sc">:</span>r0,</span>
<span id="cb2-10"><a href="#cb2-10"></a>                          <span class="cf">function</span>(a, c) <span class="fu">dbinom</span>(a, r1, p1) <span class="sc">*</span> <span class="fu">dbinom</span>(c, r0, p0))</span>
<span id="cb2-11"><a href="#cb2-11"></a>    joint_include <span class="ot">&lt;-</span> <span class="fu">outer</span>(<span class="dv">0</span><span class="sc">:</span>r1, <span class="dv">0</span><span class="sc">:</span>r0,</span>
<span id="cb2-12"><a href="#cb2-12"></a>                           <span class="cf">function</span>(a, c) <span class="fu">max</span>(a, c) <span class="sc">&gt;</span> <span class="dv">0</span> <span class="sc">&amp;</span> a <span class="sc">+</span> c <span class="sc">&lt;</span> n)</span>
<span id="cb2-13"><a href="#cb2-13"></a>    acpower <span class="ot">&lt;-</span> <span class="fu">Vectorize</span>(<span class="cf">function</span>(a, c) {</span>
<span id="cb2-14"><a href="#cb2-14"></a>      <span class="cf">if</span> (<span class="fu">max</span>(a, c) <span class="sc">&gt;</span> <span class="dv">0</span> <span class="sc">&amp;</span> a <span class="sc">+</span> c <span class="sc">&lt;</span> n) {</span>
<span id="cb2-15"><a href="#cb2-15"></a>        b <span class="ot">&lt;-</span> r1 <span class="sc">-</span> a</span>
<span id="cb2-16"><a href="#cb2-16"></a>        d <span class="ot">&lt;-</span> r0 <span class="sc">-</span> c</span>
<span id="cb2-17"><a href="#cb2-17"></a>        k1 <span class="ot">&lt;-</span> a <span class="sc">+</span> c</span>
<span id="cb2-18"><a href="#cb2-18"></a>        k0 <span class="ot">&lt;-</span> b <span class="sc">+</span> d</span>
<span id="cb2-19"><a href="#cb2-19"></a>        chisqP <span class="ot">&lt;-</span> n <span class="sc">*</span> (a <span class="sc">*</span> d <span class="sc">-</span> b <span class="sc">*</span> c)<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> (r1 <span class="sc">*</span> r0 <span class="sc">*</span> k1 <span class="sc">*</span> k0)</span>
<span id="cb2-20"><a href="#cb2-20"></a>        <span class="fu">return</span>(chisqP <span class="sc">&gt;</span> chisq_alpha)</span>
<span id="cb2-21"><a href="#cb2-21"></a>      } <span class="cf">else</span> {</span>
<span id="cb2-22"><a href="#cb2-22"></a>        <span class="fu">return</span>(<span class="dv">0</span>)</span>
<span id="cb2-23"><a href="#cb2-23"></a>      }</span>
<span id="cb2-24"><a href="#cb2-24"></a>    })</span>
<span id="cb2-25"><a href="#cb2-25"></a>    joint_power <span class="ot">&lt;-</span> <span class="fu">outer</span>(<span class="dv">0</span><span class="sc">:</span>r1, <span class="dv">0</span><span class="sc">:</span>r0, acpower)</span>
<span id="cb2-26"><a href="#cb2-26"></a>    <span class="fu">return</span>(<span class="fu">sum</span>(joint_dbinom <span class="sc">*</span> joint_power) <span class="sc">/</span> <span class="fu">sum</span>(joint_dbinom <span class="sc">*</span> joint_include))</span>
<span id="cb2-27"><a href="#cb2-27"></a>  }</span>
<span id="cb2-28"><a href="#cb2-28"></a>  r1s <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>(n <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb2-29"><a href="#cb2-29"></a>  powers <span class="ot">&lt;-</span> <span class="fu">sapply</span>(r1s, htest)</span>
<span id="cb2-30"><a href="#cb2-30"></a>  <span class="fu">return</span>(<span class="fu">data.frame</span>(<span class="at">r1 =</span> r1s, <span class="at">power =</span> powers, <span class="at">n =</span> n))</span>
<span id="cb2-31"><a href="#cb2-31"></a>}</span>
<span id="cb2-32"><a href="#cb2-32"></a></span>
<span id="cb2-33"><a href="#cb2-33"></a><span class="co"># optimal value proportion exposed (or proportion cases)</span></span>
<span id="cb2-34"><a href="#cb2-34"></a>optimphi <span class="ot">&lt;-</span> <span class="cf">function</span>(p1, p0) <span class="dv">1</span> <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">sqrt</span>(p1 <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> p1) <span class="sc">/</span> (p0 <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> p0))))</span>
<span id="cb2-35"><a href="#cb2-35"></a></span>
<span id="cb2-36"><a href="#cb2-36"></a><span class="co"># Pearson chi-squared test power for p1 = 0.1 and p0 = 0.02</span></span>
<span id="cb2-37"><a href="#cb2-37"></a>power_10_02_400 <span class="ot">&lt;-</span> <span class="fu">powers</span>(<span class="fl">0.10</span>, <span class="fl">0.02</span>, <span class="dv">400</span>)</span>
<span id="cb2-38"><a href="#cb2-38"></a>power_10_02_200 <span class="ot">&lt;-</span> <span class="fu">powers</span>(<span class="fl">0.10</span>, <span class="fl">0.02</span>, <span class="dv">200</span>)</span>
<span id="cb2-39"><a href="#cb2-39"></a>power_10_02_100 <span class="ot">&lt;-</span> <span class="fu">powers</span>(<span class="fl">0.10</span>, <span class="fl">0.02</span>, <span class="dv">100</span>)</span>
<span id="cb2-40"><a href="#cb2-40"></a></span>
<span id="cb2-41"><a href="#cb2-41"></a><span class="co"># Pearson chi-squared test power for p1 = 0.10 and p0 = 0.05</span></span>
<span id="cb2-42"><a href="#cb2-42"></a>power_10_05_400 <span class="ot">&lt;-</span> <span class="fu">powers</span>(<span class="fl">0.10</span>, <span class="fl">0.05</span>, <span class="dv">400</span>)</span>
<span id="cb2-43"><a href="#cb2-43"></a>power_10_05_200 <span class="ot">&lt;-</span> <span class="fu">powers</span>(<span class="fl">0.10</span>, <span class="fl">0.05</span>, <span class="dv">200</span>)</span>
<span id="cb2-44"><a href="#cb2-44"></a>power_10_05_100 <span class="ot">&lt;-</span> <span class="fu">powers</span>(<span class="fl">0.10</span>, <span class="fl">0.05</span>, <span class="dv">100</span>)</span>
<span id="cb2-45"><a href="#cb2-45"></a></span>
<span id="cb2-46"><a href="#cb2-46"></a><span class="co"># Pearson chi-squared test power for p1 = 0.2 and p0 = 0.02</span></span>
<span id="cb2-47"><a href="#cb2-47"></a>power_20_02_400 <span class="ot">&lt;-</span> <span class="fu">powers</span>(<span class="fl">0.20</span>, <span class="fl">0.02</span>, <span class="dv">400</span>)</span>
<span id="cb2-48"><a href="#cb2-48"></a>power_20_02_200 <span class="ot">&lt;-</span> <span class="fu">powers</span>(<span class="fl">0.20</span>, <span class="fl">0.02</span>, <span class="dv">200</span>)</span>
<span id="cb2-49"><a href="#cb2-49"></a>power_20_02_100 <span class="ot">&lt;-</span> <span class="fu">powers</span>(<span class="fl">0.20</span>, <span class="fl">0.02</span>, <span class="dv">100</span>)</span>
<span id="cb2-50"><a href="#cb2-50"></a></span>
<span id="cb2-51"><a href="#cb2-51"></a><span class="co"># Pearson chi-squared test power for p1 = 0.2 and p0 = 0.05</span></span>
<span id="cb2-52"><a href="#cb2-52"></a>power_20_05_400 <span class="ot">&lt;-</span> <span class="fu">powers</span>(<span class="fl">0.20</span>, <span class="fl">0.05</span>, <span class="dv">400</span>)</span>
<span id="cb2-53"><a href="#cb2-53"></a>power_20_05_200 <span class="ot">&lt;-</span> <span class="fu">powers</span>(<span class="fl">0.20</span>, <span class="fl">0.05</span>, <span class="dv">200</span>)</span>
<span id="cb2-54"><a href="#cb2-54"></a>power_20_05_100 <span class="ot">&lt;-</span> <span class="fu">powers</span>(<span class="fl">0.20</span>, <span class="fl">0.05</span>, <span class="dv">100</span>)</span>
<span id="cb2-55"><a href="#cb2-55"></a></span>
<span id="cb2-56"><a href="#cb2-56"></a><span class="co"># save values of graphical parameter "mar" before changing them</span></span>
<span id="cb2-57"><a href="#cb2-57"></a>orig_mar <span class="ot">&lt;-</span> <span class="fu">par</span>(<span class="st">"mar"</span>)</span>
<span id="cb2-58"><a href="#cb2-58"></a>orig_mfrow <span class="ot">&lt;-</span> <span class="fu">par</span>(<span class="st">"mfrow"</span>)</span>
<span id="cb2-59"><a href="#cb2-59"></a></span>
<span id="cb2-60"><a href="#cb2-60"></a><span class="co"># png(filename = "chisq-power.png")</span></span>
<span id="cb2-61"><a href="#cb2-61"></a><span class="fu">par</span>(<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">2</span>))</span>
<span id="cb2-62"><a href="#cb2-62"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb2-63"><a href="#cb2-63"></a></span>
<span id="cb2-64"><a href="#cb2-64"></a><span class="co"># Pearson chi-squared test power for p1 = 0.1 and p0 = 0.02</span></span>
<span id="cb2-65"><a href="#cb2-65"></a><span class="fu">plot</span>(power_10_02_400<span class="sc">$</span>r1 <span class="sc">/</span> <span class="dv">400</span>, power_10_02_400<span class="sc">$</span>power,</span>
<span id="cb2-66"><a href="#cb2-66"></a>     <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb2-67"><a href="#cb2-67"></a>     <span class="at">main =</span> <span class="fu">expression</span>(<span class="fu">paste</span>(p[<span class="dv">1</span>], <span class="st">" = 0.10"</span>, <span class="st">" and "</span>, p[<span class="dv">0</span>], <span class="st">" = 0.02"</span>)),</span>
<span id="cb2-68"><a href="#cb2-68"></a>     <span class="at">xlab =</span> <span class="st">""</span>,</span>
<span id="cb2-69"><a href="#cb2-69"></a>     <span class="at">ylab =</span> <span class="st">"Power (Pearson chi-squared test)"</span>)</span>
<span id="cb2-70"><a href="#cb2-70"></a><span class="fu">lines</span>(power_10_02_200<span class="sc">$</span>r1 <span class="sc">/</span> <span class="dv">200</span>, power_10_02_200<span class="sc">$</span>power, <span class="at">lty =</span> <span class="st">"dashed"</span>)</span>
<span id="cb2-71"><a href="#cb2-71"></a><span class="fu">lines</span>(power_10_02_100<span class="sc">$</span>r1 <span class="sc">/</span> <span class="dv">100</span>, power_10_02_100<span class="sc">$</span>power, <span class="at">lty =</span> <span class="st">"dotted"</span>)</span>
<span id="cb2-72"><a href="#cb2-72"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">"darkgray"</span>)</span>
<span id="cb2-73"><a href="#cb2-73"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">optimphi</span>(<span class="fl">0.10</span>, <span class="fl">0.02</span>), <span class="at">lty =</span> <span class="st">"dashed"</span>, <span class="at">col =</span> <span class="st">"darkgray"</span>)</span>
<span id="cb2-74"><a href="#cb2-74"></a><span class="fu">grid</span>()</span>
<span id="cb2-75"><a href="#cb2-75"></a></span>
<span id="cb2-76"><a href="#cb2-76"></a><span class="co"># Pearson chi-squared test power for p1 = 0.10 and p0 = 0.05</span></span>
<span id="cb2-77"><a href="#cb2-77"></a><span class="fu">plot</span>(power_10_05_400<span class="sc">$</span>r1 <span class="sc">/</span> <span class="dv">400</span>, power_10_05_400<span class="sc">$</span>power,</span>
<span id="cb2-78"><a href="#cb2-78"></a>     <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb2-79"><a href="#cb2-79"></a>     <span class="at">main =</span> <span class="fu">expression</span>(<span class="fu">paste</span>(p[<span class="dv">1</span>], <span class="st">" = 0.10"</span>, <span class="st">" and "</span>, p[<span class="dv">0</span>], <span class="st">" = 0.05"</span>)),</span>
<span id="cb2-80"><a href="#cb2-80"></a>     <span class="at">xlab =</span> <span class="st">""</span>, <span class="at">ylab =</span> <span class="st">""</span>)</span>
<span id="cb2-81"><a href="#cb2-81"></a><span class="fu">lines</span>(power_10_05_200<span class="sc">$</span>r1 <span class="sc">/</span> <span class="dv">200</span>, power_10_05_200<span class="sc">$</span>power, <span class="at">lty =</span> <span class="st">"dashed"</span>)</span>
<span id="cb2-82"><a href="#cb2-82"></a><span class="fu">lines</span>(power_10_05_100<span class="sc">$</span>r1 <span class="sc">/</span> <span class="dv">100</span>, power_10_05_100<span class="sc">$</span>power, <span class="at">lty =</span> <span class="st">"dotted"</span>)</span>
<span id="cb2-83"><a href="#cb2-83"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">"darkgray"</span>)</span>
<span id="cb2-84"><a href="#cb2-84"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">optimphi</span>(<span class="fl">0.10</span>, <span class="fl">0.05</span>), <span class="at">lty =</span> <span class="st">"dashed"</span>, <span class="at">col =</span> <span class="st">"darkgray"</span>)</span>
<span id="cb2-85"><a href="#cb2-85"></a><span class="fu">grid</span>()</span>
<span id="cb2-86"><a href="#cb2-86"></a><span class="fu">legend</span>(<span class="st">"topright"</span>, <span class="at">bg =</span> <span class="st">"white"</span>, <span class="at">lty =</span> <span class="fu">c</span>(<span class="st">"solid"</span>, <span class="st">"dashed"</span>, <span class="st">"dotted"</span>),</span>
<span id="cb2-87"><a href="#cb2-87"></a>       <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">"n = 400"</span>, <span class="st">"n = 200"</span>, <span class="st">"n = 100"</span>))</span>
<span id="cb2-88"><a href="#cb2-88"></a></span>
<span id="cb2-89"><a href="#cb2-89"></a><span class="co"># Pearson chi-squared test power for p1 = 0.2 and p0 = 0.02</span></span>
<span id="cb2-90"><a href="#cb2-90"></a><span class="fu">plot</span>(power_20_02_400<span class="sc">$</span>r1 <span class="sc">/</span> <span class="dv">400</span>, power_20_02_400<span class="sc">$</span>power,</span>
<span id="cb2-91"><a href="#cb2-91"></a>     <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb2-92"><a href="#cb2-92"></a>     <span class="at">main =</span> <span class="fu">expression</span>(<span class="fu">paste</span>(p[<span class="dv">1</span>], <span class="st">" = 0.20"</span>, <span class="st">" and "</span>, p[<span class="dv">0</span>], <span class="st">" = 0.02"</span>)),</span>
<span id="cb2-93"><a href="#cb2-93"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">"Proportion exposed ("</span>, phi, <span class="st">")"</span>)),</span>
<span id="cb2-94"><a href="#cb2-94"></a>     <span class="at">ylab =</span> <span class="st">"Power (Pearson chi-squared test)"</span>)</span>
<span id="cb2-95"><a href="#cb2-95"></a><span class="fu">lines</span>(power_20_02_200<span class="sc">$</span>r1 <span class="sc">/</span> <span class="dv">200</span>, power_20_02_200<span class="sc">$</span>power, <span class="at">lty =</span> <span class="st">"dashed"</span>)</span>
<span id="cb2-96"><a href="#cb2-96"></a><span class="fu">lines</span>(power_20_02_100<span class="sc">$</span>r1 <span class="sc">/</span> <span class="dv">100</span>, power_20_02_100<span class="sc">$</span>power, <span class="at">lty =</span> <span class="st">"dotted"</span>)</span>
<span id="cb2-97"><a href="#cb2-97"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">"darkgray"</span>)</span>
<span id="cb2-98"><a href="#cb2-98"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">optimphi</span>(<span class="fl">0.20</span>, <span class="fl">0.02</span>), <span class="at">lty =</span> <span class="st">"dashed"</span>, <span class="at">col =</span> <span class="st">"darkgray"</span>)</span>
<span id="cb2-99"><a href="#cb2-99"></a><span class="fu">grid</span>()</span>
<span id="cb2-100"><a href="#cb2-100"></a></span>
<span id="cb2-101"><a href="#cb2-101"></a><span class="co"># Pearson chi-squared test power for p1 = 0.2 and p0 = 0.05</span></span>
<span id="cb2-102"><a href="#cb2-102"></a><span class="fu">plot</span>(power_20_05_400<span class="sc">$</span>r1 <span class="sc">/</span> <span class="dv">400</span>, power_20_05_400<span class="sc">$</span>power,</span>
<span id="cb2-103"><a href="#cb2-103"></a>     <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb2-104"><a href="#cb2-104"></a>     <span class="at">main =</span> <span class="fu">expression</span>(<span class="fu">paste</span>(p[<span class="dv">1</span>], <span class="st">" = 0.20"</span>, <span class="st">" and "</span>, p[<span class="dv">0</span>], <span class="st">" = 0.05"</span>)),</span>
<span id="cb2-105"><a href="#cb2-105"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">"Proportion exposed ("</span>, phi, <span class="st">")"</span>)),</span>
<span id="cb2-106"><a href="#cb2-106"></a>     <span class="at">ylab =</span> <span class="st">""</span></span>
<span id="cb2-107"><a href="#cb2-107"></a>    <span class="co">#  ylab = "Power (Pearson chi-squared test)"</span></span>
<span id="cb2-108"><a href="#cb2-108"></a>     )</span>
<span id="cb2-109"><a href="#cb2-109"></a><span class="fu">lines</span>(power_20_05_200<span class="sc">$</span>r1 <span class="sc">/</span> <span class="dv">200</span>, power_20_05_200<span class="sc">$</span>power, <span class="at">lty =</span> <span class="st">"dashed"</span>)</span>
<span id="cb2-110"><a href="#cb2-110"></a><span class="fu">lines</span>(power_20_05_100<span class="sc">$</span>r1 <span class="sc">/</span> <span class="dv">100</span>, power_20_05_100<span class="sc">$</span>power, <span class="at">lty =</span> <span class="st">"dotted"</span>)</span>
<span id="cb2-111"><a href="#cb2-111"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">"darkgray"</span>)</span>
<span id="cb2-112"><a href="#cb2-112"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">optimphi</span>(<span class="fl">0.20</span>, <span class="fl">0.05</span>), <span class="at">lty =</span> <span class="st">"dashed"</span>, <span class="at">col =</span> <span class="st">"darkgray"</span>)</span>
<span id="cb2-113"><a href="#cb2-113"></a><span class="fu">grid</span>()</span>
<span id="cb2-114"><a href="#cb2-114"></a><span class="co"># dev.off()</span></span>
<span id="cb2-115"><a href="#cb2-115"></a></span>
<span id="cb2-116"><a href="#cb2-116"></a><span class="co"># reset graphical parameters "mar" and "mfrow"</span></span>
<span id="cb2-117"><a href="#cb2-117"></a><span class="fu">par</span>(<span class="at">mar =</span> orig_mar)</span>
<span id="cb2-118"><a href="#cb2-118"></a><span class="fu">par</span>(<span class="at">mfrow =</span> orig_mfrow)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<!-- ```{r filename="chisq-power.R"}
#| label: fig-chisq-power
#| fig-cap: "The power of the Pearson chi-squared test from a cohort study as a function of the proportion of the sample exposed ($\\varphi$) at several combinations of $p_1$ and $p_0$ for $n = 400/tab$ (solid), $n = 200$ (dashed), and $n = 100$ (dotted). There is a dark gray solid line at $\\varphi = 0.5$, representing a balanced study, and a dark gray dashed line at $\\varphi^*$ from @eq-optimphi. The same power is achieved by a case control study where $\\pi_1$ replaces $p_1$, $\\pi_0$ replaces $p_0$, and $\\varphi$ is the proportion of the sample who are cases."
#| fig-height: 7
#| fig-width: 7


## Actual power of a Pearson chi-squared test

# calculate Pearson chi-squared test power
# This can take a few minutes to run with large n.
powers <- function(p1, p0, n, level = 0.95) {
  chisq_alpha <- qchisq(level, df = 1)
  htest <- function(r1) {
    r0 <- n - r1
    joint_dbinom <- outer(0:r1, 0:r0,
                          function(a, c) dbinom(a, r1, p1) * dbinom(c, r0, p0))
    joint_include <- outer(0:r1, 0:r0,
                           function(a, c) max(a, c) > 0 & a + c < n)
    acpower <- Vectorize(function(a, c) {
      if (max(a, c) > 0 & a + c < n) {
        b <- r1 - a
        d <- r0 - c
        k1 <- a + c
        k0 <- b + d
        chisqP <- n * (a * d - b * c)^2 / (r1 * r0 * k1 * k0)
        return(chisqP > chisq_alpha)
      } else {
        return(0)
      }
    })
    joint_power <- outer(0:r1, 0:r0, acpower)
    return(sum(joint_dbinom * joint_power) / sum(joint_dbinom * joint_include))
  }
  r1s <- 1:(n - 1)
  powers <- sapply(r1s, htest)
  return(data.frame(r1 = r1s, power = powers, n = n))
}

# optimal value proportion exposed (or proportion cases)
optimphi <- function(p1, p0) 1 / (1 + sqrt(p1 * (1 - p1) / (p0 * (1 - p0))))

# Pearson chi-squared test power for p1 = 0.1 and p0 = 0.02
power_10_02_400 <- powers(0.10, 0.02, 400)
power_10_02_200 <- powers(0.10, 0.02, 200)
power_10_02_100 <- powers(0.10, 0.02, 100)

# Pearson chi-squared test power for p1 = 0.10 and p0 = 0.05
power_10_05_400 <- powers(0.10, 0.05, 400)
power_10_05_200 <- powers(0.10, 0.05, 200)
power_10_05_100 <- powers(0.10, 0.05, 100)

# Pearson chi-squared test power for p1 = 0.2 and p0 = 0.02
power_20_02_400 <- powers(0.20, 0.02, 400)
power_20_02_200 <- powers(0.20, 0.02, 200)
power_20_02_100 <- powers(0.20, 0.02, 100)

# Pearson chi-squared test power for p1 = 0.2 and p0 = 0.05
power_20_05_400 <- powers(0.20, 0.05, 400)
power_20_05_200 <- powers(0.20, 0.05, 200)
power_20_05_100 <- powers(0.20, 0.05, 100)

# save values of graphical parameter "mar" before changing them
orig_mar <- par("mar")
orig_mfrow <- par("mfrow")

# png(filename = "chisq-power.png")
par(mar = c(4, 4, 3, 2))
par(mfrow = c(2, 2))

# Pearson chi-squared test power for p1 = 0.1 and p0 = 0.02
plot(power_10_02_400$r1 / 400, power_10_02_400$power,
     type = "l", ylim = c(0, 1),
     main = expression(paste(p[1], " = 0.10", " and ", p[0], " = 0.02")),
     xlab = "",
     ylab = "Power (Pearson chi-squared test)")
lines(power_10_02_200$r1 / 200, power_10_02_200$power, lty = "dashed")
lines(power_10_02_100$r1 / 100, power_10_02_100$power, lty = "dotted")
abline(v = 0.5, col = "darkgray")
abline(v = optimphi(0.10, 0.02), lty = "dashed", col = "darkgray")
grid()

# Pearson chi-squared test power for p1 = 0.10 and p0 = 0.05
plot(power_10_05_400$r1 / 400, power_10_05_400$power,
     type = "l", ylim = c(0, 1),
     main = expression(paste(p[1], " = 0.10", " and ", p[0], " = 0.05")),
     xlab = "", ylab = "")
lines(power_10_05_200$r1 / 200, power_10_05_200$power, lty = "dashed")
lines(power_10_05_100$r1 / 100, power_10_05_100$power, lty = "dotted")
abline(v = 0.5, col = "darkgray")
abline(v = optimphi(0.10, 0.05), lty = "dashed", col = "darkgray")
grid()
legend("topright", bg = "white", lty = c("solid", "dashed", "dotted"),
       legend = c("n = 400", "n = 200", "n = 100"))

# Pearson chi-squared test power for p1 = 0.2 and p0 = 0.02
plot(power_20_02_400$r1 / 400, power_20_02_400$power,
     type = "l", ylim = c(0, 1),
     main = expression(paste(p[1], " = 0.20", " and ", p[0], " = 0.02")),
     xlab = expression(paste("Proportion exposed (", phi, ")")),
     ylab = "Power (Pearson chi-squared test)")
lines(power_20_02_200$r1 / 200, power_20_02_200$power, lty = "dashed")
lines(power_20_02_100$r1 / 100, power_20_02_100$power, lty = "dotted")
abline(v = 0.5, col = "darkgray")
abline(v = optimphi(0.20, 0.02), lty = "dashed", col = "darkgray")
grid()

# Pearson chi-squared test power for p1 = 0.2 and p0 = 0.05
plot(power_20_05_400$r1 / 400, power_20_05_400$power,
     type = "l", ylim = c(0, 1),
     main = expression(paste(p[1], " = 0.20", " and ", p[0], " = 0.05")),
     xlab = expression(paste("Proportion exposed (", phi, ")")),
     ylab = ""
    #  ylab = "Power (Pearson chi-squared test)"
     )
lines(power_20_05_200$r1 / 200, power_20_05_200$power, lty = "dashed")
lines(power_20_05_100$r1 / 100, power_20_05_100$power, lty = "dotted")
abline(v = 0.5, col = "darkgray")
abline(v = optimphi(0.20, 0.05), lty = "dashed", col = "darkgray")
grid()
# dev.off()

# reset graphical parameters "mar" and "mfrow"
par(mar = orig_mar)
par(mfrow = orig_mfrow)


``` -->
</section>
</section>
<section id="case-control-studies" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="case-control-studies"><span class="header-section-number">7.4</span> Case-control studies</h2>
<p>The Pearson chi-squared statistic <span class="math inline">\(\chisqP\)</span> from <a href="#eq-chisqP2" class="quarto-xref">Equation&nbsp;<span>7.7</span></a> can also be rewritten in terms of the prevalence of exposure among <strong>cases</strong> (participants who have disease or disease onset) and <strong>controls</strong> (participants who do not have disease or disease onset). This leads to the <strong>case-control</strong> study design.</p>
<section id="selection-by-disease" class="level3" data-number="7.4.1">
<h3 data-number="7.4.1" class="anchored" data-anchor-id="selection-by-disease"><span class="header-section-number">7.4.1</span> Selection by disease</h3>
<p>As above, let <span class="math inline">\(\pi_1\)</span> be the exposure prevalence in cases and <span class="math inline">\(\pi_0\)</span> be the exposure prevalence in controls. Their maximum likelihood estimates are <span class="math inline">\(\hat{\pi}_1 = a / k_1\)</span> and <span class="math inline">\(\hat{\pi}_0 = c / k_0\)</span>, so the maximum likelihood estimate of <span class="math inline">\(\pi_1 - \pi_0\)</span> is <span id="eq-chi2Pcc-num"><span class="math display">\[
  \hat{\pi}_1 - \hat{\pi}_0
  = \frac{a}{a + c} - \frac{b}{b + d}
  = \frac{a d - b c}{(a + c) (b + d)}
  = \frac{a d - b c}{k_1 k_0}.
\tag{7.16}\]</span></span> <a href="#sec-indep-condprob" class="quarto-xref"><span>Section 7.2.1</span></a> showed that null hypothesis that exposure and disease are independent is equivalent to <span class="math inline">\(H_0: \pi_1 = \pi_0 = \pi\)</span> where <span class="math inline">\(\pi\)</span> is the marginal prevalence of exposure.</p>
<p>In large samples under the null, <span class="math inline">\(\A\)</span> has a binomial(<span class="math inline">\(k_1\)</span>, <span class="math inline">\(\pi\)</span>) conditional distribution, <span class="math inline">\(\B\)</span> has a binomial(<span class="math inline">\(k_0\)</span>, <span class="math inline">\(\pi\)</span>) conditional distribution, and they are conditionally independent given the column sums <span class="math inline">\(k_1\)</span> and <span class="math inline">\(k_0\)</span>. Thus, the large-sample variance of <span class="math inline">\(\hat{\pi}_1 - \hat{\pi}_0\)</span> under the null is <span id="eq-casecontrol-den"><span class="math display">\[
  \Var_0(\hat{\pi}_1 - \hat{\pi}_0)
  = \pi (1 - \pi) \bigg(\frac{1}{k_1} + \frac{1}{k_0}\bigg)
  = \pi (1 - \pi) \frac{n}{k_1 k_0}
\tag{7.17}\]</span></span> where we used <span class="math inline">\(k_1 + k_0 = n\)</span>. Replacing the unknown <span class="math inline">\(\pi\)</span> with its maximum likelihood estimate <span class="math inline">\(\hat{\pi} = r_1 / n\)</span>, we get the estimated null variance <span id="eq-chi2Pcc-den"><span class="math display">\[
  \hat{\Var}_0(\hat{\pi}_1 - \hat{\pi}_0)
  = \hat{\pi} (1 - \hat{\pi}) \frac{n}{k_1 k_0}
  = \frac{r_1 r_0}{k_1 k_0 n}
\tag{7.18}\]</span></span> where we used <span class="math inline">\(1 - \hat{\pi} = r_0 / n\)</span>. Combining the results in <a href="#eq-chi2Pcc-num" class="quarto-xref">Equation&nbsp;<span>7.16</span></a>} and <a href="#eq-chi2Pcc-den" class="quarto-xref">Equation&nbsp;<span>7.18</span></a>, we get <span class="math display">\[
  \frac{(\hat{\pi}_1 - \hat{\pi}_0)^2}{\hat{\Var}_0(\hat{\pi}_1 - \hat{\pi}_0)}
  = \frac{n (a d - b c)^2}{r_1 r_0 k_1 k_0}
  = \chisqP
\]</span> (see <a href="#eq-chisqP2" class="quarto-xref">Equation&nbsp;<span>7.7</span></a>). The LLN guarantees that <span class="math inline">\(\hat{\pi}_1 \rightarrow \pi_1\)</span> as <span class="math inline">\(k_1 \rightarrow \infty\)</span> and that <span class="math inline">\(\hat{\pi}_0 \rightarrow \pi_0\)</span> as <span class="math inline">\(k_0 \rightarrow \infty\)</span>. In large samples, <span id="eq-chisqP-largecc"><span class="math display">\[
  \chisqP \approx \frac{(\pi_1 - \pi_0)^2}{\pi (1 - \pi) \Big(\frac{1}{k_1} + \frac{1}{k_0}\Big)}
\tag{7.19}\]</span></span> because the sample average <span class="math display">\[
  \frac{k_1 \pi_1 + k_0 \pi_0}{n} \rightarrow \pi
\]</span> as <span class="math inline">\(n \rightarrow \infty\)</span> by the LLN. The numerator of <a href="#eq-chisqP-largecc" class="quarto-xref">Equation&nbsp;<span>7.19</span></a> is fixed, but the denominator depends on <span class="math inline">\(k_1\)</span> and <span class="math inline">\(k_0\)</span>. By sampling according to disease status, we can choose <span class="math inline">\(k_1\)</span> and <span class="math inline">\(k_0\)</span> to increase the power of the Pearson chi-squared test for a fixed total number of participants.</p>
</section>
<section id="score-test-for-independence-in-a-case-control-study" class="level3" data-number="7.4.2">
<h3 data-number="7.4.2" class="anchored" data-anchor-id="score-test-for-independence-in-a-case-control-study"><span class="header-section-number">7.4.2</span> Score test for independence in a case-control study*</h3>
<p>As with sampling by exposure in a cohort study, sampling by disease in a case-control study does not affect the score test of the null hypothesis that exposure and disease are independent. Using a binomial(<span class="math inline">\(k_1\)</span>, <span class="math inline">\(\pi_1\)</span>) distribution for the number of exposed cases and a binomial(<span class="math inline">\(k_0\)</span>, <span class="math inline">\(\pi_0\)</span>) distribution for the number of exposed controls, we get the log likelihood <span class="math display">\[
  \ell(\pi_1, \pi_0) = \A \ln \pi_1 + \C \ln(1 - \pi_1) + \B \ln \pi_0 + \D \ln(1 - \pi_0)
\]</span> as a random variable whose value will be determined by the data. Calculating the score <span class="math inline">\(U(\pi, \pi)\)</span> and the expected information <span class="math inline">\(\mathcal{I}(\pi, \pi)\)</span> under the null hypothesis <span class="math inline">\(H_0: \pi_1 = \pi_0 = \pi\)</span> and evaluating them at <span class="math inline">\(\hat{\pi} = r_1 / n\)</span>, we get <span class="math display">\[
  U(\hat{\pi}, \hat{\pi})
  = \begin{pmatrix}
    \frac{a}{\hat{\pi}} + \frac{c}{1 - \hat{\pi}} \\[5pt]
    \frac{b}{\hat{\pi}} + \frac{d}{1 - \hat{\pi}}
  \end{pmatrix}
  = \begin{pmatrix}
      \frac{n (a d - b c)}{r_1 r_0} \\[5pt]
      - \frac{n (a d - b c)}{r_1 r_0}
    \end{pmatrix}
\]</span> and <span class="math display">\[
  \mathcal{I}(\hat{\pi}, \hat{\pi})
  = \begin{bmatrix}
      \frac{k_1 n^2}{r_1 r_0} &amp; 0 \\
      0                       &amp; \frac{k_0 n^2}{r_1 r_0}
    \end{bmatrix}
  \;\Rightarrow\;
  \mathcal{I}^{\,-1}(\hat{\pi}, \hat{\pi})
  = \begin{bmatrix}
      \frac{r_1 r_0}{k_1 n^2} &amp; 0 \\
      0                       &amp; \frac{r_1 r_0}{k_0 n^2}
    \end{bmatrix}
\]</span> The score statistic is <span class="math display">\[
  U(\hat{\pi}, \hat{\pi})^\transpose \mathcal{I}(\hat{\pi}, \hat{\pi})^{-1} U(\hat{\pi}, \hat{\pi})
  = \frac{n (a d - b c)^2}{r_1 r_0 k_1 k_0}
  = \chisqP,
\]</span> which is the Pearson chi-squared statistic from <a href="#eq-chisqP2" class="quarto-xref">Equation&nbsp;<span>7.7</span></a>. The null hypothesis reduces the degrees of freedom from two (<span class="math inline">\(\pi_1\)</span> and <span class="math inline">\(\pi_0\)</span>) to one (<span class="math inline">\(\pi_1 = \pi_0 = \pi\)</span>), so the score statistic has a <span class="math inline">\(\chi^2_1\)</span> distribution under <span class="math inline">\(H_0\)</span>. Therefore, Pearson’s chi-squared test is the score test of the null hypothesis <span class="math inline">\(H_0: \pi_0 = \pi_1\)</span> in a case-control study. The column sums <span class="math inline">\(k_1\)</span> and <span class="math inline">\(k_0\)</span> are fixed by design, and we condition on the row sums <span class="math inline">\(r_1\)</span> and <span class="math inline">\(r_0\)</span> because we use the maximum likelihood estimate <span class="math inline">\(\hat{\pi} = r_1 / n\)</span> for the prevalence of exposure under <span class="math inline">\(H_0\)</span>. Because of the invariance of the score test when it uses the expected information, any parameterization of the model for the exposure prevalences <span class="math inline">\(\pi_1\)</span> and <span class="math inline">\(\pi_0\)</span> leads to the same test of the null hypothesis that exposure and disease are independent.</p>
</section>
<section id="optimal-sampling-by-disease" class="level3" data-number="7.4.3">
<h3 data-number="7.4.3" class="anchored" data-anchor-id="optimal-sampling-by-disease"><span class="header-section-number">7.4.3</span> Optimal sampling by disease</h3>
<p>Having established that <span class="math inline">\(\chisqP\)</span> is the score statistic for testing the independence of exposure and disease in a case-control study, we can choose <span class="math inline">\(k_1\)</span> and <span class="math inline">\(k_0\)</span> to maximize the power of the test for a given number of participants <span class="math inline">\(n = k_1 + k_0\)</span>. Let <span class="math inline">\(\varphi\)</span> be the proportion of the sample who are cases. Then <span class="math display">\[
  \begin{aligned}
    k_1   &amp;= \varphi n \\
    k_0   &amp;= (1 - \varphi) n \\
    \pi   &amp;= \varphi \pi_1 + (1 - \varphi) \pi_0.
  \end{aligned}
\]</span> Substituting these into equation <a href="#eq-casecontrol-den" class="quarto-xref">Equation&nbsp;<span>7.17</span></a> and simplifying gives us the denominator as a function of <span class="math inline">\(\varphi\)</span>: <span class="math display">\[
  \frac{n \pi (1 - \pi)}{k_1 k_0}
  = \frac{\varphi}{1 - \varphi} \pi_1 (1 - \pi_1) + \frac{1 - \varphi}{\varphi} \pi_0 (1 - \pi_0) + C(\pi_1, \pi_0)
\]</span> where <span class="math inline">\(C(\pi_1, \pi_0) = \pi_1 (1 - \pi_0) + \pi_0 (1 - \pi_1)\)</span> does not depend on <span class="math inline">\(\varphi\)</span>. This is identical to The derivative with respect to <span class="math inline">\(\varphi\)</span> is <span class="math display">\[
  \frac{\dif}{\dif \varphi} \frac{n \pi (1 - \pi)}{r_1 r_0}
  = \frac{\pi_1 (1 - \pi_1)}{(1 - \varphi)^2} - \frac{\pi_0 (1 - \pi_0)}{\varphi^2}.
\]</span> This is identical to <a href="#eq-deriv-phi" class="quarto-xref">Equation&nbsp;<span>7.13</span></a> if we replace <span class="math inline">\(p_1\)</span> with <span class="math inline">\(\pi_1\)</span> and <span class="math inline">\(p_0\)</span> with <span class="math inline">\(\pi_0\)</span>, so the same argument used in <a href="#sec-optim-cohort" class="quarto-xref"><span>Section 7.3.3</span></a> tells us that the Pearson chi-squared statistic <span class="math inline">\(\chisqP\)</span> from a case-control study is maximized when the proportion of the sample comprised of cases is <span id="eq-optimphi-cc"><span class="math display">\[
  \varphi^*
  = \frac{1}{1 + \sqrt{\frac{\pi_1 (1 - \pi_1)}{\pi_0 (1 - \pi_0)}}}.
\tag{7.20}\]</span></span> Here, the expression inside the square root is the variance of a Bernoulli(<span class="math inline">\(\pi_1\)</span>) random variable divided by the variance of a Bernoulli(<span class="math inline">\(\pi_0\)</span>) random variable. <a href="#fig-optim-phi" class="quarto-xref">Figure&nbsp;<span>7.1</span></a> shows how <span class="math inline">\(\phi^*\)</span> depends on this variance ratio. When <span class="math inline">\(\pi_1 \approx \pi_0\)</span>, the Bernoulli variance ratio is approximately one <span class="math inline">\(\phi^* \approx 0.5\)</span>.</p>
<p>The power functions shown in <a href="#fig-chisq-power" class="quarto-xref">Figure&nbsp;<span>7.2</span></a> apply to a case-control study if we replace <span class="math inline">\(p_1\)</span> with <span class="math inline">\(\pi_1\)</span> and <span class="math inline">\(p_0\)</span> with <span class="math inline">\(\pi_0\)</span>. The justification for recruiting equal numbers of cases and controls in a case-control study is exactly the same as that for recruiting equal numbers of exposed and unexposed in a cohort study: When testing the null hypothesis can be justified, a balanced study is almost always optimal or near-optimal in terms of its power to detect an association between exposure and disease <span class="citation" data-cites="walter1977determination">(<a href="references.html#ref-walter1977determination" role="doc-biblioref">Walter 1977</a>)</span>.</p>
</section>
</section>
<section id="sec-design-choice" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="sec-design-choice"><span class="header-section-number">7.5</span> Choice of study design</h2>
<p>We have shown that the power of the Pearson and hypergeometric chi-squared tests can be increased by sampling participants according to exposure (in a cohort study) or disease (in a case-control study) instead of taking a random sample from the population. It remains to see how to choose between a cohort study and a case-control study.</p>
<section id="sec-ORdesign" class="level3" data-number="7.5.1">
<h3 data-number="7.5.1" class="anchored" data-anchor-id="sec-ORdesign"><span class="header-section-number">7.5.1</span> Odds ratio</h3>
<p>To choose between the cohort and case-control study designs, it is extremely helpful that the estimated odds ratio is the same for all three study designs. In <a href="#tbl-2x2observed" class="quarto-xref">Table&nbsp;<span>7.2</span></a>, the estimated odds ratio comparing the risks of disease in the exposed (numerator) and the unexposed (denominator) is <span class="math display">\[
  \frac{\odds(\hat{p}_1)}{\odds(\hat{p}_0)}
  = \frac{a / b}{c / d}
  = \frac{a d}{b c}
\]</span> where <span class="math inline">\(r_1\)</span> canceled out of the numerator and <span class="math inline">\(r_0\)</span> canceled out of the denominator in the middle expression. The estimated odds ratio comparing the prevalence exposure in cases (numerator) and controls (denominator) is <span class="math display">\[
  \frac{\odds(\hat{\pi}_1)}{\odds(\hat{\pi}_0)}
  = \frac{a / b}{c / d}
  = \frac{a d}{b c}
\]</span> where <span class="math inline">\(k_1\)</span> canceled out of the numerator and <span class="math inline">\(k_0\)</span> canceled out of the denominator in the middle expression. The Pearson chi-squared statistic can be rewritten in terms of the odds ratio: <span class="math display">\[
  \chisqP
  = \frac{n \big(\frac{a d}{b c} - 1\big)^2 b^2 c^2}{r_1 r_0 k_1 k_0}
  = \frac{n (\hat{\OR} - 1)^2 b^2 c^2}{r_1 r_0 k_1 k_0}.
\]</span> Let <span class="math display">\[
  \Delta_n
  = n (\hat{\OR} - 1),
\]</span> which does not depend on which study design we use.</p>
<p>A random sample from the population has <span class="math display">\[
  \chisqP
  = \Delta_n \hat{p}_0 (1 - \hat{p}_1) \hat{\pi}_0 (1 - \hat{\pi}_1).
\]</span> because <span class="math inline">\(b = r_1 (1 - \hat{p}_1) = k_0 \hat{\pi}_0\)</span> and <span class="math inline">\(c = r_0 \hat{p}_0 = k_1 (1 - \hat{\pi}_1)\)</span>. Close to the null hypothesis, <span class="math inline">\(\hat{p}_1 \approx \hat{p}_0 \approx \hat{p}\)</span> and <span class="math inline">\(\hat{\pi}_0 \approx \hat{\pi}_1 \approx \hat{\pi}\)</span>. In large samples close to the null hypothesis, <span class="math display">\[
  \chisqP \approx \Delta_n p (1 - p) \pi (1 - \pi).
\]</span> because <span class="math inline">\(\hat{p} \rightarrow p\)</span> and <span class="math inline">\(\hat{\pi} \rightarrow \pi\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span> by the LLN. A balanced cohort study has <span class="math inline">\(r_0 = r_1 = n / 2\)</span> and <span class="math display">\[
  \chisqP
  = \frac{\Delta_n (1 - \hat{p}_1)^2 \hat{p}_0^2}{4 \hat{p} (1 - \hat{p})}.
\]</span> because <span class="math inline">\(b c = n^2 (1 - \hat{p}_1) \hat{p}_0 / 4\)</span> and <span class="math inline">\(k_1 k_0 = n^2 \hat{p} (1 - \hat{p})\)</span>. In a large sample close to (but not under) the null hypothesis, <span class="math display">\[
  \chisqP
  \approx \frac{\Delta_n p^2 (1 - p)^2}{4 p (1 - p)}
  = \frac{\Delta_n}{4} p (1 - p).
\]</span> Following similar logic for a case-control study, we get <span class="math display">\[
  \chisqP
  \approx \frac{\Delta_n}{4} \pi (1 - \pi)
\]</span> in large samples near the null hypothesis. Because <span class="math inline">\(v (1 - v) \leq 1 / 4\)</span> for <span class="math inline">\(v \in [0, 1]\)</span>, the <span class="math inline">\(\chisqP\)</span> statistics from the cohort and case-control studies are both upper bounds for the <span class="math inline">\(\chisqP\)</span> statistic from a random sample of the population.</p>
<p>Close to the null, a cohort study will be more powerful than a case-control study when <span class="math display">\[
  p (1 - p) &gt; \pi (1 - \pi)
\]</span> and a case-control study will be more powerful than a cohort study when <span class="math display">\[
  p (1 - p) &lt; \pi (1 - \pi).
\]</span> The advantage of a cohort study will be greatest for a rare exposure and a risk of disease close to <span class="math inline">\(1 / 2\)</span>, and the advantage of a case-control study will be greatest for rare disease and a prevalence of exposure close to <span class="math inline">\(1 / 2\)</span>. Both study designs are always more powerful than a random sample from the population.</p>
</section>
<section id="imbalance-and-efficiency-on-a-fixed-budget" class="level3" data-number="7.5.2">
<h3 data-number="7.5.2" class="anchored" data-anchor-id="imbalance-and-efficiency-on-a-fixed-budget"><span class="header-section-number">7.5.2</span> Imbalance and efficiency on a fixed budget</h3>
<p>Even when testing the null hypothesis is defensible, an imbalanced study design can be justified when one exposure or disease group is substantially more difficult or expensive to recruit than the other. In a cohort study with a rare exposure, exposed individuals might be harder to recruit than unexposed individuals. In a case-control study with a rare disease, cases might be harder to recruit than controls. Even when the greatest power for a given number of participants is achieved with a balanced study, the greatest power for a given study’s resources may occur with imbalanced groups.</p>
<p>Deliberately imbalanced designs are used most often in case-control studies, but the principle is the same in cohort studies. Let <span class="math inline">\(C\)</span> be the ratio of the cost of recruiting a case to that of recruiting a control, and <span class="math inline">\(B\)</span> be the budget of the study (expressed as the total number of controls that could be enrolled if no cases were enrolled). As in <a href="#tbl-2x2observed" class="quarto-xref">Table&nbsp;<span>7.2</span></a>, <span class="math inline">\(k_1\)</span> is the number of cases and <span class="math inline">\(k_0\)</span> is the number of controls. We need to minimize the variance of <span class="math inline">\(\hat{\pi}_1 - \hat{\pi}_0\)</span> from <a href="#eq-casecontrol-den" class="quarto-xref">Equation&nbsp;<span>7.17</span></a> given that <span class="math display">\[
  k_1 C + k_0 = B.
\]</span> For simplicity, we will assume that the prevalences of exposure <span class="math inline">\(\pi_1\)</span> (in cases) and <span class="math inline">\(\pi_0\)</span> (in controls) are approximately equal, so we can ignore the fact that <span class="math inline">\(\hat{\pi}\)</span> depends on <span class="math inline">\(\varphi = k_1 / n\)</span>.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> To maximize the value of <span class="math inline">\(\chisqP\)</span> close to (but not under) the null, we need to minimize <span class="math display">\[
  \frac{1}{k_1} + \frac{1}{k_0} = \frac{1}{k_1} + \frac{1}{B - k_1 C}
\]</span> over <span class="math inline">\(k_1\)</span> The derivative with respect to <span class="math inline">\(k_1\)</span> is <span class="math display">\[
  \frac{\dif}{\dif k_1} \bigg(\frac{1}{k_1} + \frac{1}{B - k_1 C}\bigg)
  = -\frac{1}{k_1^2} + \frac{C}{(B - k_1 C)^2},
\]</span> which equals zero when <span class="math display">\[
  k_0^2 = k_1^2 C.
\]</span> This corresponds to <span class="math inline">\(k_0 = k_1 \sqrt{C}\)</span> or recruiting <span class="math inline">\(\sqrt{C}\)</span> controls per case <span class="citation" data-cites="miettinen1969individual nam1973optimum gail1976many">(<a href="references.html#ref-miettinen1969individual" role="doc-biblioref">Miettinen 1969</a>; <a href="references.html#ref-nam1973optimum" role="doc-biblioref">Nam 1973</a>; <a href="references.html#ref-gail1976many" role="doc-biblioref">Gail et al. 1976</a>)</span>. The optimal proportion of the sample who are cases is <span class="math display">\[
  \varphi^*_C = \frac{1}{1 + \sqrt{C}}.
\]</span> A nearly identical argument based on <a href="#eq-cohort-den" class="quarto-xref">Equation&nbsp;<span>7.9</span></a> shows that this <span class="math inline">\(\varphi^*_C\)</span> is also the optimal proportion exposed in a cohort study where the cost of recruiting an exposed individual is <span class="math inline">\(C\)</span> times that of recruiting an unexposed individual. This <span class="math inline">\(\sqrt{C}\)</span> rule is a good approximation to more accurate and complicated optimal sampling rules <span class="citation" data-cites="meydrech1978cost pike1979re morgenstern1983method">(<a href="references.html#ref-meydrech1978cost" role="doc-biblioref">Meydrech and Kupper 1978</a>; <a href="references.html#ref-pike1979re" role="doc-biblioref">Pike and Casagrande 1979</a>; <a href="references.html#ref-morgenstern1983method" role="doc-biblioref">Morgenstern and Winn 1983</a>)</span>.</p>
<p>With a total sampling budget of <span class="math inline">\(B\)</span>, the optimal numbers of cases is <span class="math display">\[
    k_1^* = \frac{B}{\sqrt{C} + C}
\]</span> and the optimal number of controls is <span class="math display">\[
    k_0^* = k_1^* \sqrt{C} = \frac{B}{1 + \sqrt{C}}.
\]</span> The minimum variance of the risk difference that we can achieve near the null is proportional to <span class="math display">\[
  V^* = \frac{1}{k_1^*} + \frac{1}{k_0^*}
  = \frac{\left(1 + \sqrt{C}\right)^2}{B}.
\]</span> If we use a balanced study design, <span class="math inline">\(k_1 = k_0 = B / (1 + C)\)</span> and the variance of the risk difference is proportional to <span class="math display">\[
  V^\text{bal} = \frac{2}{k_1} = \frac{2 (1 + C)}{B}.
\]</span> For any given budget <span class="math inline">\(B\)</span>, the asymptotic relative efficiency of the optimal study compared to a balanced study is <span class="math display">\[
  \frac{V^\text{bal}}{V^*} = \frac{2 (1 + C)}{\big(1 + \sqrt{C}\big)^2}.
\]</span> It is plotted as a function of <span class="math inline">\(C\)</span> in <a href="#fig-optimal-budget" class="quarto-xref">Figure&nbsp;<span>7.3</span></a>. The difference is small for moderate values of <span class="math inline">\(C\)</span>, with relative efficiencies of approximately <span class="math inline">\(1.029\)</span> for <span class="math inline">\(C = 2\)</span> and <span class="math inline">\(1.146\)</span> for <span class="math inline">\(C = 5\)</span>. In extreme scenarios (i.e., as <span class="math inline">\(C \rightarrow 0\)</span> or <span class="math inline">\(C \rightarrow \infty\)</span>), the optimal study is twice as efficient as a balanced study with the same budget <span class="citation" data-cites="nam1973optimum">(<a href="references.html#ref-nam1973optimum" role="doc-biblioref">Nam 1973</a>)</span>.</p>
<div class="cell">
<div class="code-with-filename">
<details class="code-fold">
<summary>Code</summary>
<div class="code-with-filename-file">
<pre><strong>optimal-budget.R</strong></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a><span class="do">## Relative efficiency of imbalanced study design on fixed budget</span></span>
<span id="cb3-2"><a href="#cb3-2"></a></span>
<span id="cb3-3"><a href="#cb3-3"></a><span class="co"># variance ratio comparing balanced study to budget-optimal study</span></span>
<span id="cb3-4"><a href="#cb3-4"></a>logC <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb3-5"><a href="#cb3-5"></a>releff <span class="ot">&lt;-</span> <span class="cf">function</span>(C) <span class="dv">2</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">+</span> C) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">sqrt</span>(C))<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb3-6"><a href="#cb3-6"></a><span class="fu">plot</span>(logC, <span class="fu">releff</span>(<span class="fu">exp</span>(logC)), <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">2</span>), <span class="at">xaxt =</span> <span class="st">"n"</span>,</span>
<span id="cb3-7"><a href="#cb3-7"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">"Cost ratio "</span>, <span class="fu">italic</span>(<span class="st">"C"</span>), <span class="st">" (log scale)"</span>)),</span>
<span id="cb3-8"><a href="#cb3-8"></a>     <span class="at">ylab =</span> <span class="st">"Asymptotic relative efficiency of budget-optimal study"</span>)</span>
<span id="cb3-9"><a href="#cb3-9"></a><span class="fu">axis</span>(<span class="dv">1</span>, <span class="at">at =</span> <span class="fu">log</span>(<span class="fu">c</span>(<span class="dv">1</span> <span class="sc">/</span> <span class="fu">c</span>(<span class="dv">20</span>, <span class="dv">10</span>, <span class="dv">5</span>, <span class="dv">2</span>), <span class="dv">1</span>, <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">20</span>))),</span>
<span id="cb3-10"><a href="#cb3-10"></a>     <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"1/20"</span>, <span class="st">"1/10"</span>, <span class="st">"1/5"</span>, <span class="st">"1/2"</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">20</span>))</span>
<span id="cb3-11"><a href="#cb3-11"></a><span class="fu">grid</span>()</span>
<span id="cb3-12"><a href="#cb3-12"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">"darkgray"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell-output-display">
<div id="fig-optimal-budget" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-optimal-budget-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="studydesign_files/figure-html/fig-optimal-budget-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;7.3: The asymptotic relative efficiency of an optimal case-control study compared to a balanced study with the same budget when recruiting a case costs C times as much as recruiting a control. There is a dark gray line at a relative efficiency of one. The same relative efficiency applies to cohort studies when recruiting an exposed individual costs C times as much as recruiting an unexposed individual."><img src="studydesign_files/figure-html/fig-optimal-budget-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-optimal-budget-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.3: The asymptotic relative efficiency of an optimal case-control study compared to a balanced study with the same budget when recruiting a case costs <span class="math inline">\(C\)</span> times as much as recruiting a control. There is a dark gray line at a relative efficiency of one. The same relative efficiency applies to cohort studies when recruiting an exposed individual costs <span class="math inline">\(C\)</span> times as much as recruiting an unexposed individual.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The relative efficiency can thought of as the ratio of the sampling budgets of a balanced study and an optimal study that achieve the same power <span class="citation" data-cites="nam1973optimum gail1976many">(<a href="references.html#ref-nam1973optimum" role="doc-biblioref">Nam 1973</a>; <a href="references.html#ref-gail1976many" role="doc-biblioref">Gail et al. 1976</a>)</span>. Thus, a balanced study requires at most twice the budget of an optimal study to achieve the same power. <span class="citation" data-cites="brittain1981cost">Brittain, Schlesselman, and Stadel (<a href="references.html#ref-brittain1981cost" role="doc-biblioref">1981</a>)</span> found that sampling costs were approximately 33-66% of total costs in five case-control studies funded by the National Institute of Child Health and Human Development in the 1970s. Compared to a balanced study design, they found that optimal sampling of cases and controls would reduce total study costs by at most 8.5% for <span class="math inline">\(C \leq 5\)</span> and at most 4.5% for <span class="math inline">\(C \leq 3\)</span>. As usual, balanced study designs are close to optimal.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-agresti2012categorical" class="csl-entry" role="listitem">
Agresti, Alan. 2013. <em>Categorical Data Analysis</em>. Third. Vol. 792. John Wiley &amp; Sons.
</div>
<div id="ref-blaker2000confidence" class="csl-entry" role="listitem">
Blaker, Helge. 2000. <span>“Confidence Curves and Improved Exact Confidence Intervals for Discrete Distributions.”</span> <em>Canadian Journal of Statistics</em> 28 (4): 783–98.
</div>
<div id="ref-boos2013essential" class="csl-entry" role="listitem">
Boos, Dennis D, and Leonard A Stefanski. 2013. <em>Essential Statistical Inference</em>. Springer.
</div>
<div id="ref-brittain1981cost" class="csl-entry" role="listitem">
Brittain, Erica, James J Schlesselman, and Bruce V Stadel. 1981. <span>“Cost of Case-Control Studies.”</span> <em>American Journal of Epidemiology</em> 114 (2): 234–43.
</div>
<div id="ref-fay2010confidence" class="csl-entry" role="listitem">
Fay, Michael P. 2010. <span>“Confidence Intervals That Match Fisher’s Exact or Blaker’s Exact Tests.”</span> <em>Biostatistics</em> 11 (2): 373–74.
</div>
<div id="ref-fisher1922interpretation" class="csl-entry" role="listitem">
Fisher, Ronald A. 1922. <span>“On the Interpretation of <span class="math inline">\(\chi\)</span> 2 from Contingency Tables, and the Calculation of p.”</span> <em>Journal of the Royal Statistical Society</em> 85 (1): 87–94.
</div>
<div id="ref-fisher1935logic" class="csl-entry" role="listitem">
———. 1935. <span>“The Logic of Inductive Inference.”</span> <em>Journal of the Royal Statistical Society</em> 98 (1): 39–82.
</div>
<div id="ref-freedman2007can" class="csl-entry" role="listitem">
Freedman, David A. 2007. <span>“How Can the Score Test Be Inconsistent?”</span> <em>The American Statistician</em> 61 (4): 291–95.
</div>
<div id="ref-gail1976many" class="csl-entry" role="listitem">
Gail, Mitchell, Roger Williams, David P Byar, Charles Brown, et al. 1976. <span>“How Many Controls?”</span> <em>Journal of Chronic Diseases</em> 29 (11): 723–31.
</div>
<div id="ref-hill1965environment" class="csl-entry" role="listitem">
Hill, Sir Austin Bradford. 1965. <span>“The Environment and Disease: Association or Causation?”</span> <em>Proceedings of the Royal Society of Medicine</em> 58: 295–300.
</div>
<div id="ref-irwin1935tests" class="csl-entry" role="listitem">
Irwin, JO et al. 1935. <span>“Tests of Significance for Differences Between Percentages Based on Small Numbers.”</span> <em>Metron</em> 12 (2): 84–94.
</div>
<div id="ref-lancaster1961significance" class="csl-entry" role="listitem">
Lancaster, H Oliver. 1961. <span>“Significance Tests in Discrete Distributions.”</span> <em>Journal of the American Statistical Association</em> 56 (294): 223–34.
</div>
<div id="ref-meydrech1978cost" class="csl-entry" role="listitem">
Meydrech, Edward F, and Lawrence L Kupper. 1978. <span>“Cost Considerations and Sample Size Requirements in Cohort and Case-Control Studies.”</span> <em>American Journal of Epidemiology</em> 107 (3): 201–5.
</div>
<div id="ref-miettinen1969individual" class="csl-entry" role="listitem">
Miettinen, Olli S. 1969. <span>“Individual Matching with Multiple Controls in the Case of All-or-None Responses.”</span> <em>Biometrics</em> 25 (2): 339–55.
</div>
<div id="ref-morgenstern1983method" class="csl-entry" role="listitem">
Morgenstern, Hal, and Deborah M Winn. 1983. <span>“A Method for Determining the Sampling Ratio in Epidemiologic Studies.”</span> <em>Statistics in Medicine</em> 2 (3): 387–96.
</div>
<div id="ref-nam1973optimum" class="csl-entry" role="listitem">
Nam, Jun-Mo. 1973. <span>“Optimum Sample Sizes for the Comparison of the Control and Treatment.”</span> <em>Biometrics</em> 29: 101–8.
</div>
<div id="ref-pearson1900x" class="csl-entry" role="listitem">
Pearson, Karl. 1900. <span>“On the Criterion That a Given System of Deviations from the Probable in the Case of a Correlated System of Variables Is Such That It Can Be Reasonably Supposed to Have Arisen from Random Sampling.”</span> <em>The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science</em> 50 (302): 157–75.
</div>
<div id="ref-pearson1922chi" class="csl-entry" role="listitem">
———. 1922. <span>“On the <span class="math inline">\(\chi\)</span> 2 Test of Goodness of Fit.”</span> <em>Biometrika</em> 14 (1/2): 186–91.
</div>
<div id="ref-pike1979re" class="csl-entry" role="listitem">
Pike, MC, and JT Casagrande. 1979. <span>“Re:<span>‘cost Considerations and Sample Size Requirements in Cohort and Case-Control Studies’</span>.”</span> <em>American Journal of Epidemiology</em> 110 (1): 100–102.
</div>
<div id="ref-rao1948large" class="csl-entry" role="listitem">
Rao, C Radhakrishna. 1948. <span>“Large Sample Tests of Statistical Hypotheses Concerning Several Parameters with Applications to Problems of Estimation.”</span> In <em>Mathematical Proceedings of the Cambridge Philosophical Society</em>, 44:50–57. Cambridge University Press.
</div>
<div id="ref-roscoe1971investigation" class="csl-entry" role="listitem">
Roscoe, John T, and Jackson A Byars. 1971. <span>“An Investigation of the Restraints with Respect to Sample Size Commonly Imposed on the Use of the Chi-Square Statistic.”</span> <em>Journal of the American Statistical Association</em> 66 (336): 755–59.
</div>
<div id="ref-routledge1992resolving" class="csl-entry" role="listitem">
Routledge, RD. 1992. <span>“Resolving the Conflict over Fisher’s Exact Test.”</span> <em>Canadian Journal of Statistics</em> 20 (2): 201–9.
</div>
<div id="ref-walter1977determination" class="csl-entry" role="listitem">
Walter, Samuel D. 1977. <span>“Determination of Significant Relative Risks and Optimal Sampling Procedures in Prospective and Retrospective Comparative Studies of Various Sizes.”</span> <em>American Journal of Epidemiology</em> 105 (4): 387–97.
</div>
</div>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p> The distribution of the cell counts in <a href="#tbl-2x2random" class="quarto-xref">Table&nbsp;<span>7.1</span></a> is exactly multinomial (and each cell count and row or column total is exactly binomial) if we sample with replacement.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p> Named after <a href="https://en.wikipedia.org/wiki/Karl_Pearson">Karl Pearson</a> (1857–1936), an English statistician who appeared in the context of the Pearson correlation coefficient in <a href="probability.html#sec-varcov" class="quarto-xref"><span>Section 1.4.2</span></a>. <a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p> These rules of thumb are for chi-squared tests with one degree of freedom and significance level <span class="math inline">\(\alpha = 0.05\)</span>. Smaller <span class="math inline">\(\alpha\)</span> require larger average cell counts to estimate smaller p-values accurately, and chi-squared tests with more than one degree of freedom are more robust to small expected cell counts <span class="citation" data-cites="roscoe1971investigation">(<a href="references.html#ref-roscoe1971investigation" role="doc-biblioref">Roscoe and Byars 1971</a>)</span>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p> Inversion of the minimum likelihood Fisher’s or Blaker’s exact tests can produce confidence regions for the odds ratio that consist of two disjoint intervals, but inversion of the central Fisher’s exact test always produces a confidence region that consists of a single interval <span class="citation" data-cites="fay2010confidence">(<a href="references.html#ref-fay2010confidence" role="doc-biblioref">Fay 2010</a>)</span>.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p> Without this assumption, it is difficult or impossible to derive an explicit expression for the optimal ratio <span class="math inline">\(\varphi^*\)</span> because the total sample size <span class="math inline">\(n\)</span> depends on <span class="math inline">\(\varphi\)</span>, which complicates the derivatives. An optimal ratio can be calculated numerically.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./survival.html" class="pagination-link" aria-label="One-Sample Survival Analysis">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">One-Sample Survival Analysis</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./validity.html" class="pagination-link" aria-label="Internal and External Validity">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Internal and External Validity</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>